{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8103db4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notebook 1: Merging and annotating tables and matrix tables, Sample QC, PCA outlier removal, Variant QC\n",
    "\n",
    "To do:\n",
    "1. add in plotting code generated by Ally & make sure it runs\n",
    "2. add more detailed descriptions of why each step is run\n",
    "3. remove certain table/mt write-outs\n",
    "4. potentially (need to discuss with Mary first) write a function to read data\n",
    "5. create more detailed index\n",
    "\n",
    "---------------------\n",
    "\n",
    "Notebook 3: Sequencing/diversity and QC metrics notebook\n",
    "\n",
    "Plots that need to be added to nb (currently in the works by Ally) \n",
    "1. Contamination/Freemix - sample_filters.contamination and bam_metrics.freemix - *DONE*\n",
    "2. Heterozygosity - plot distribution to show how it doesn’t work with diverse popns as expected (e.g. high for AFR, low for FIN) - *PENDING*\n",
    "3. Plot fail_n_snp_residual and using that as an example, explain the rest in the description - the plots were created early on in the project showing which gnomAD QC filters were dropping whole populations. Currently in R, but needs to be implemented in Hail - *PENDING*\n",
    "\n",
    "---------------------\n",
    "Further edits needed in this nb:\n",
    "- Add Ally's code for plots "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc89c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Index\n",
    "1. [Data Management Function](#1.-Data-Management-Function)\n",
    "2. [Read in Datasets and Annotate](#2.-Read-in-Datasets-and-Annotate)\n",
    "3. [Investigating gnomAD sample filters](#3.-Investigating-gnomAD-sample-filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a5426",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# General Overview\n",
    "The purpose of this script is to merge metadata components needed for the HGDP+1kGP dataset and then run  QC filters on that resulting dataset. The metadata included sample and variant information such as geographic region, and which samples/variants passed QC were initially located in different datasets. The QC filters were run using sample/variant flags from the metadata datasets. These flags were generated as a result of the dataset being run through the gnomAD QC pipeline. More information on the gnomAD QC pipeline can be found [here](https://gnomad.broadinstitute.org/news/2020-10-gnomad-v3-1-new-content-methods-annotations-and-data-availability/#sample-and-variant-quality-control). To see how these filters were updated as a result of our analyses, see [gnomAD sample filters](#3.-Investigating-gnomAD-sample-filters) and the resulting gnomAD [minor release.](https://gnomad.broadinstitute.org/news/2021-10-gnomad-v3-1-2-minor-release/#improvements-to-the-hgdp--1kg-subset-release)\n",
    "\n",
    "**This script contains information on how to**:\n",
    "- Annotate new fields onto a matrix table from another matrix table or hail table\n",
    "- Unflatten a hail matrix table\n",
    "- Harmonize datasets to prevent merge conflicts\n",
    "- Use plots to identify which gnomAD QC filters are removing populations entirely (fail_n_snp_residual used as an example)\n",
    "- Retrieve populations being unduly removed by filters (mostly AFR and OCE populations)\n",
    "- Filter matrix tables using a field within the matrix table\n",
    "- Filter samples using a hardcoded list of samples to remove\n",
    "- Plot certain fields from the matrix table:\n",
    "    - Contamination\n",
    "    - Freemix\n",
    "    - Heterozygosity (plot distribution to show how it doesn’t work with diverse populations as expected (e.g. high for AFR, low for FIN)\n",
    "\n",
    "**Datasets merged are**:\n",
    "- sample_meta: sample metadata table which contains harmonized metadata for the HGDP_1kGP dataset\n",
    "- sample_qc_meta: gnomad v3.1 sample qc metadata from for the hgdp_1kg subset which contains flags to denote which samples failed gnomAD QC filters\n",
    "- var_meta: hail matrix table with a field of flags (mt.filters) to denote which variants passed or failed gnomAD qc filters\n",
    "- dense_mt: densified hgdp_1kg matrix table\n",
    "\n",
    "Authors: Zan Koenig & Mary T. Yohannes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fd0022",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import hail\n",
    "import hail as hl\n",
    "\n",
    "# for renaming purposes\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d670566",
   "metadata": {},
   "source": [
    "## Set Requester Pays Bucket\n",
    "Running through these tutorials, users must specify which project is to be billed. To change which project is billed, set the `GCP_PROJECT_NAME` variable to your own project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting requester pays bucket to use throughout tutorial\n",
    "GCP_PROJECT_NAME = \"diverse-pop-seq-ref\"\n",
    "hl.init(spark_conf={\n",
    "    'spark.hadoop.fs.gs.requester.pays.mode': 'CUSTOM',\n",
    "    'spark.hadoop.fs.gs.requester.pays.buckets': 'hgdp_tgp,gcp-public-data--gnomad',\n",
    "    'spark.hadoop.fs.gs.requester.pays.project.id': 'diverse-pop-seq-ref'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba907f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Data Management Function\n",
    "This function serves the purpose of reading in the dataset of different stages throughout the tutorial and given certain flags, will allow the user to specify which filters they would like run on the dataset. This function helps to reduce the amount of times data needs to be written out, overall decreasing the computational and monetary cost of running the tutorials. \n",
    "\n",
    "<details>\n",
    "    <summary><br>The arguments of the function are as follows: \n",
    "        <br>[click <span style=\"color:green\">here</span> to expand]</summary>\n",
    "<br> \n",
    "Click on each argument name to learn more!\n",
    "\n",
    "<details><summary><br> \n",
    "- <span style=\"color:green\">default</span></summary> \n",
    "    \n",
    "<p>when <i><b>True</b></i>, will return a pre-QC matrix table</p></details>\n",
    "\n",
    "<details><summary><br> \n",
    "- <span style=\"color:green\">post_qc</span></summary> \n",
    "    \n",
    "<p>when <i><b>True</b></i>, will return a matrix table which has the following conducted:</p>\n",
    "<ul> \n",
    "    <li>sample_qc filtering</li>\n",
    "    <li>variant_qc filtering</li>\n",
    "    <li>outlier removal</li>\n",
    "    <li>duplicate removal</li>  \n",
    "    </ul></details>\n",
    "\n",
    "\n",
    "<details><summary><br>   \n",
    "- <span style=\"color:green\">sample_qc</span></summary>     \n",
    "    \n",
    "<p>when <i><b>True</b></i>, will return a matrix table with gnomad's sampleQC filters run on the dataset. For more information on gnomAD's sample QC steps click <a href=\"https://gnomad.broadinstitute.org/news/2020-10-gnomad-v3-1-new-content-methods-annotations-and-data-availability/#sample-qc-hard-filtering\"> here.</a></p></details>    \n",
    "    \n",
    "<details><summary><br>   \n",
    "- <span style=\"color:green\">variant_qc</span></summary>     \n",
    "    \n",
    "<p>when <i><b>True</b></i>, will return a matrix table with gnomad's variant quality control filters run on the dataset. For more information on gnomAD's variant QC steps click <a href=\"https://gnomad.broadinstitute.org/news/2020-10-gnomad-v3-1-new-content-methods-annotations-and-data-availability/#variant-qc\"> here.</a></p></details>        \n",
    "\n",
    "<details><summary><br>   \n",
    "- <span style=\"color:green\">duplicate</span></summary>     \n",
    "    \n",
    "<p>when <i><b>True</b></i>, will return a matrix table with any duplicates in the dataset removed. By default there are no duplicates in the dataset, but was included as it is a useful QC step to demonstrate</p></details> \n",
    "  \n",
    "<details><summary><br>\n",
    "- <span style=\"color:green\">outlier_removal</span></summary>     \n",
    "    \n",
    "<p>when <i><b>True</b></i>, will return a matrix table with pca outliers removed. These outliers were determined by running pc_relate. More information on how we created the outlier list can be found <a href=\"https://nbviewer.org/github/atgu/hgdp_tgp/blob/master/tutorials/nb4.ipynb#5.-Outlier-Removal\"> here.</a></p></details> \n",
    "    \n",
    "<details><summary><br>   \n",
    "- <span style=\"color:green\">ld_pruning</span></summary>     \n",
    "   \n",
    "<p>when <i><b>True</b></i>, will return a matrix table which has the following conducted:</p>\n",
    "<ul> \n",
    "    <li>sample_qc filtering</li>\n",
    "    <li>variant_qc filtering</li>\n",
    "    <li>outlier removal</li>\n",
    "    <li>duplicate removal</li>\n",
    "    <li>call rate filter to variants whose call rate is > 0.999</li>\n",
    "    <li>allele frequency filter on variants to only keep variants with 0.05 < AF < 0.95</li>\n",
    "    </ul></details>   \n",
    "    \n",
    "<details><summary><br>\n",
    "- <span style=\"color:green\">rel_unrel</span></summary>  \n",
    "\n",
    "<p>when <i><b>default</b></i>, will return the same matrix table which would be returned when ld_pruning=True</p>\n",
    "\n",
    "<p>when <i><b>related</b></i>, will return a matrix table with only related samples</p>\n",
    "\n",
    "<p>when <i><b>unrelated</b></i> will return matrix table with only unrelated samples</p></details>\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9aa0ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_qc(\n",
    "        default: bool = False,\n",
    "        post_qc:bool = False,\n",
    "        sample_qc: bool = False,\n",
    "        variant_qc: bool = False,\n",
    "        duplicate: bool = False,\n",
    "        outlier_removal: bool = False,\n",
    "        ld_pruning: bool = False,\n",
    "        rel_unrel: str = 'default') -> hl.MatrixTable:\n",
    "    \"\"\"\n",
    "    Wrapper function to get HGDP+1kGP data as Matrix Table at different stages of QC/filtering.\n",
    "    By default, returns pre QC MatrixTable with qc filters annotated but not filtered.\n",
    "\n",
    "    :param bool default: if True will preQC version of the dataset\n",
    "    :param bool post_qc: if True will return a post QC matrix table that has gone through:\n",
    "        - sample QC\n",
    "        - variant QC\n",
    "        - duplicate removal\n",
    "        - outlier removal\n",
    "    :param bool sample_qc: if True will return a post sample QC matrix table\n",
    "    :param bool variant_qc: if True will return a post variant QC matrix table\n",
    "    :param bool duplicate: if True will return a matrix table with duplicate samples removed\n",
    "    :param bool outlier_removal: if True will return a matrix table with PCA outliers and duplicate samples removed\n",
    "    :param bool ld_pruning: if True will return a matrix table that has gone through:\n",
    "        - sample QC\n",
    "        - variant QC\n",
    "        - PCA outlier removal\n",
    "        - duplicate removal\n",
    "        - LD pruning\n",
    "        - additional variant filtering\n",
    "    :param bool rel_unrel: default will return same mt as ld pruned above\n",
    "        if 'related' will return a matrix table with only related samples.\n",
    "        if 'unrelated' will return a matrix table with only unrelated samples\n",
    "    \"\"\"\n",
    "    # Reading in all the tables and matrix tables needed to generate the pre_qc matrix table\n",
    "    sample_meta = hl.import_table('gs://hgdp-1kg/hgdp_tgp/qc_and_figure_generation/gnomad_meta_v1.tsv')\n",
    "    sample_qc_meta = hl.read_table('gs://hgdp_tgp/output/gnomad_v3.1_sample_qc_metadata_hgdp_tgp_subset.ht')\n",
    "    var_meta = hl.read_table(\n",
    "        'gs://hgdp-1kg/hgdp_tgp/qc_and_figure_generation/gnomad_v3_sites_filters_only.ht')\n",
    "    dense_mt = hl.read_matrix_table(\n",
    "        'gs://gcp-public-data--gnomad/release/3.1.2/mt/genomes/gnomad.genomes.v3.1.2.hgdp_1kg_subset_dense.mt')\n",
    "    \n",
    "    var_meta = var_meta.naive_coalesce(5000)\n",
    "    dense_mt = dense_mt.naive_coalesce(5000)\n",
    "\n",
    "\n",
    "    # Takes a list of dicts and converts it to a struct format (works with nested structs too)\n",
    "    def dict_to_struct(d):\n",
    "        fields = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                v = dict_to_struct(v)\n",
    "            fields[k] = v\n",
    "        return hl.struct(**fields)\n",
    "\n",
    "    # un-flattening a hail table with nested structure\n",
    "    # dict to hold struct names as well as nested field names\n",
    "    d = {}\n",
    "\n",
    "    # Getting the row field names\n",
    "    row = sample_meta.row_value\n",
    "\n",
    "    # returns a dict with the struct names as keys and their inner field names as values\n",
    "    for name in row:\n",
    "        def recur(dict_ref, split_name):\n",
    "            if len(split_name) == 1:\n",
    "                dict_ref[split_name[0]] = row[name]\n",
    "                return\n",
    "            existing = dict_ref.get(split_name[0])\n",
    "            if existing is not None:\n",
    "                assert isinstance(existing, dict), existing\n",
    "                recur(existing, split_name[1:])\n",
    "            else:\n",
    "                existing = {}\n",
    "                dict_ref[split_name[0]] = existing\n",
    "                recur(existing, split_name[1:])\n",
    "        recur(d, name.split('.'))\n",
    "\n",
    "    # using the dict created from flattened struct, creating new structs now un-flattened\n",
    "    sample_meta = sample_meta.select(**dict_to_struct(d))\n",
    "    sample_meta = sample_meta.key_by('s')\n",
    "\n",
    "    # grabbing the columns needed from Alicia's metadata\n",
    "    new_meta = sample_meta.select(sample_meta.hgdp_tgp_meta, sample_meta.bergstrom)\n",
    "\n",
    "    # creating a table with gnomAD sample metadata and HGDP metadata\n",
    "    ht = sample_qc_meta.annotate(**new_meta[sample_qc_meta.s])\n",
    "\n",
    "    # stripping 'v3.1::' from the names to match with the densified MT\n",
    "    ht = ht.key_by(s=ht.s.replace(\"v3.1::\", \"\"))\n",
    "\n",
    "    # Using hl.annotate_cols() method to annotate the gnomAD variant QC metadata onto the matrix table\n",
    "    mt = dense_mt.annotate_cols(**ht[dense_mt.s])\n",
    "\n",
    "    # annotating preQC dataset with variant metadata\n",
    "    mt = mt.annotate_rows(**var_meta[mt.locus, mt.alleles])\n",
    "\n",
    "    print(f\"sample_qc: {sample_qc}\\nvariant_qc: {variant_qc}\\nduplicate: {duplicate}\\noutlier_removal: { outlier_removal}\\nld_pruning: {ld_pruning}\\nrel_unrel: {rel_unrel}\")\n",
    "    \n",
    "    if default:\n",
    "        print(\"Returning default preQC matrix table\")\n",
    "        # returns preQC dataset\n",
    "        return mt\n",
    "    \n",
    "    if post_qc:\n",
    "        print(\"Returning post sample and variant QC matrix table with duplicates and PCA outliers removed\")\n",
    "        sample_qc = True\n",
    "        variant_qc = True\n",
    "        duplicate = True\n",
    "        outlier_removal = True\n",
    "    \n",
    "    if sample_qc:\n",
    "        print(\"Running sample QC\")\n",
    "        # run data through sample QC\n",
    "        # filtering samples to those who should pass gnomADs sample QC\n",
    "        # this filters to only samples that passed gnomad sample QC hard filters\n",
    "        mt = mt.filter_cols(~mt.sample_filters.hard_filtered)\n",
    "\n",
    "        # annotating partially filtered dataset with variant metadata\n",
    "        mt = mt.annotate_rows(**var_meta[mt.locus, mt.alleles])\n",
    "\n",
    "    if variant_qc:\n",
    "        print(\"Running variant QC\")\n",
    "        # run data through variant QC\n",
    "        # Subsetting the variants in the dataset to only PASS variants (those which passed gnomAD's variant QC)\n",
    "        # PASS variants are variants which have an entry in the filters field.\n",
    "        # This field contains an array which contains a bool if any variant qc filter was failed\n",
    "        # This is the last step in the QC process\n",
    "        mt = mt.filter_rows(hl.len(mt.filters) != 0, keep=False)\n",
    "\n",
    "    if duplicate:\n",
    "        print(\"Removing any duplicate samples\")\n",
    "        # Removing any duplicates in the dataset using hl.distinct_by_col() which removes\n",
    "        # columns with a duplicate column key. It keeps one column for each unique key.\n",
    "        # after updating to the new dense_mt, this step is no longer necessary to run\n",
    "        mt = mt.distinct_by_col()\n",
    "\n",
    "    if outlier_removal:\n",
    "        print(\"Removing PCA outliers\")\n",
    "        # remove PCA outliers and duplicates\n",
    "        # reading in the PCA outlier list\n",
    "        # To read in the PCA outlier list, first need to read the file in as a list\n",
    "        # using hl.hadoop_open here which allows one to read in files into hail from Google cloud storage\n",
    "        pca_outlier_path = 'gs://hgdp-1kg/hgdp_tgp/pca_outliers_v2.txt'\n",
    "        with hl.utils.hadoop_open(pca_outlier_path) as file:\n",
    "            outliers = [line.rstrip('\\n') for line in file]\n",
    "\n",
    "        # Using hl.literal here to convert the list from a python object to a hail expression so that it can be used\n",
    "        # to filter out samples\n",
    "        outliers_list = hl.literal(outliers)\n",
    "\n",
    "        # Using the list of PCA outliers, using the ~ operator which is a negation operator and obtains the compliment\n",
    "        # In this case the compliment is samples which are not contained in the pca outlier list\n",
    "        mt = mt.filter_cols(~outliers_list.contains(mt['s']))\n",
    "\n",
    "    if ld_pruning:\n",
    "        print(\"Returning ld pruned post variant and sample QC matrix table pre PCA outlier removal \")\n",
    "        # read in dataset which has additional variant filtering and ld pruning run\n",
    "        # data has gone through:\n",
    "        #   - sample QC\n",
    "        #   - variant QC\n",
    "        #   - duplicate removal\n",
    "        mt = hl.read_matrix_table('gs://hgdp-1kg/hgdp_tgp/intermediate_files/filtered_n_pruned_output_updated.mt')\n",
    "\n",
    "    if rel_unrel == \"all\":\n",
    "        print(\"Returning ld pruned post sample and variant \\\n",
    "              QC matrix table pre PCA outlier removal with related & unrelated individuals\")\n",
    "        # need to check what steps this dataset has gone through, this is something to discuss with Mary\n",
    "        # data has gone through:\n",
    "        #   - sample QC\n",
    "        #   - variant QC\n",
    "        #   - duplicate removal\n",
    "        #   - LD pruning\n",
    "        mt = hl.read_matrix_table('gs://hgdp-1kg/hgdp_tgp/intermediate_files/filtered_n_pruned_output_updated.mt')\n",
    "\n",
    "    elif rel_unrel == 'related':\n",
    "        print(\"Returning post sample and variant QC matrix table \\\n",
    "              pre PCA outlier removal with only related individuals\")\n",
    "        # data has gone through:\n",
    "        #   - sample QC\n",
    "        #   - variant QC\n",
    "        #   - duplicate removal\n",
    "        #   - LD pruning\n",
    "        #   - pc_relate - filter to only related individuals\n",
    "        mt = hl.read_matrix_table('gs://hgdp-1kg/hgdp_tgp/rel_updated.mt')\n",
    "\n",
    "        \n",
    "    elif rel_unrel == 'unrelated':\n",
    "        print(\"Returning post QC matrix table with only unrelated individuals\")\n",
    "        # data has gone through:\n",
    "        #   - sample QC\n",
    "        #   - variant QC\n",
    "        #   - duplicate removal\n",
    "        #   - LD pruning\n",
    "        #   - pc_relate - filter to only unrelated individuals\n",
    "        mt = hl.read_matrix_table('gs://hgdp-1kg/hgdp_tgp/unrel_updated.mt')\n",
    "        \n",
    "    # Calculating both variant and sample_qc metrics on the mt before returning\n",
    "    # so the stats are up to date with the version being written out\n",
    "    mt = hl.sample_qc(mt)\n",
    "    mt = hl.variant_qc(mt)\n",
    "    \n",
    "    return mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c2534",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Read in Datasets and Annotate\n",
    "<br>\n",
    "<details>\n",
    "<summary>More about the input dataset \n",
    "     <br>[click <span style=\"color:green\">here</span> to expand] </summary>\n",
    "\n",
    "    This input matrix table is a combination of 3 datasets: a harmonized sample metadata for the HGDP+1KG dataset, a gnomAD v3.1 sample qc metadata with samples that failed gnomAD QC filters flagged, and a densified HGDP+1KG matrix table.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary> More information on Hail methods and expressions\n",
    "    <br>[click <span style=\"color:green\">here</span> to expand] </summary>\n",
    "<ul>\n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/impex.html#hail.methods.read_matrix_table\"> More on  <i> read_matrix_table() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.count\"> More on  <i> count() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/impex.html#hail.methods.read_table\"> More on  <i> read_table() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.annotate_rows\"> More on  <i> annotate_rows() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.expr.Expression.html#hail.expr.Expression.describe\"> More on  <i> describe() </i></a></li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf08e53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read-in the matrix table (shortened as mt)\n",
    "mt = read_qc(default=True)\n",
    "\n",
    "# how many snps and samples are there? counts \n",
    "print('Num of snps and samples prior to any analysis = ' + str(mt.count())) # 211358784 snps & 4151 samples \n",
    "\n",
    "# read in variant QC metadata containing information on which variants passed/failed gnomAD QC filters\n",
    "var_meta = hl.read_table('gs://gcp-public-data--gnomad/release/3.1.1/ht/genomes/gnomad.genomes.v3.1.1.sites.ht')\n",
    "\n",
    "# annotate variant QC metadata onto mt \n",
    "mt = mt.annotate_rows(**var_meta[mt.locus, mt.alleles]) \n",
    "\n",
    "# explore combined mt \n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea10d07",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Investigating gnomAD sample filters\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary> Why are we doing this? \n",
    "    <br>[click <span style=\"color:green\">here</span> to expand] </summary>\n",
    "    \n",
    "9 out of the 28 gnomAD sample filters were dropping huge numbers of ancestrally diverse individuals (mostly African (AFR) and Oceanian (OCE) populations). The filters use gnomAD’s principal component analysis (PCA) which is obtained from other samples to residualize the distribution of values from different populations and identify outliers. If there is an error and outliers are identified, the sample fails the filter. \n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary> More information on Hail methods and expressions \n",
    "    <br>[click <span style=\"color:green\">here</span> to expand] </summary>\n",
    "<ul>\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.filter_cols\"> More on  <i> filter_cols() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.expr.SetExpression.html#hail.expr.SetExpression.difference\"> More on  <i> difference() </i></a></li>\n",
    "\n",
    "<li><a href=\" https://hail.is/docs/0.2/hail.expr.CollectionExpression.html#hail.expr.CollectionExpression.length\"> More on  <i> length() </i></a></li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a856b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# put the gnomAD qc filters in a set \n",
    "all_sample_filters = set(mt['sample_filters']) \n",
    "\n",
    "# select out the filters that are removing whole populations despite them passing all other gnomAD filters\n",
    "# if a filter name starts with 'fail_', add it to a new set after removing 'fail_' from the name  \n",
    "bad_sample_filters = {re.sub('fail_', '', x) for x in all_sample_filters if x.startswith('fail_')} \n",
    "\n",
    "# filter out the samples that passed all gnomad QC filters OR only failed the filters that were removing population wholly\n",
    "mt_filt = mt.filter_cols(mt['sample_filters']['qc_metrics_filters'].difference(bad_sample_filters).length() == 0)\n",
    "\n",
    "# how many samples were removed by the initial QC?\n",
    "print('Num of samples before initial QC = ' + str(mt.count()[1])) # 4151\n",
    "print('Num of samples after initial QC = ' + str(mt_filt.count()[1])) # 4120\n",
    "print('Samples removed = ' + str(mt.count()[1] - mt_filt.count()[1])) # 31"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

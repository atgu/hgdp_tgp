{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47062d02",
   "metadata": {},
   "source": [
    "# Metadata and QC\n",
    "\n",
    "Author: Zan Koenig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc89c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Index\n",
    "1. [Data Management Function](#1.-Data-Management-Function)\n",
    "2. [Read in Datasets and Annotate](#2.-Read-in-Datasets-and-Annotate)\n",
    "3. [Investigating gnomAD Sample Filters](#3.-Investigating-gnomAD-sample-filters)\n",
    "4. [Plotting Results of gnomAD Sample Filter Investigation](#-4.-Plotting-results-of-gnomAD-sample-filter-investigation)\n",
    "5. [Pre-QC Plots](#5.-Pre-QC-Plots)\n",
    "    1. [Number of SNPs](#5a-Number-of-SNPs)\n",
    "    2. [Mean Coverage](#5b-Mean-Coverage)\n",
    "    3. [Freemix](#5c-Freemix)\n",
    "6. [Post-QC Plots](#6.-Post-QC-Plots)\n",
    "    1. [Number of SNPs](#6a-Number-of-SNPs)\n",
    "    2. [Mean Coverage](#6b-Mean-Coverage)\n",
    "    3. [Freemix](#6c-Freemix)\n",
    "    4. [Site Frequency Spectrum](#6d-Site-Frequency-Spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a5426",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# General Overview\n",
    "The purpose of this script is to merge metadata components needed for the HGDP+1kGP dataset and then apply QC filters on that resulting dataset. The metadata included sample and variant information (e.g. geographic region, and which samples/variants passed QC) that were initially located in different datasets. The QC filters were run using sample and variant flags from the metadata datasets. These flags were generated as a result of the dataset being run through the gnomAD QC pipeline. More information on the gnomAD QC pipeline can be found [here](https://gnomad.broadinstitute.org/news/2020-10-gnomad-v3-1-new-content-methods-annotations-and-data-availability/#sample-and-variant-quality-control). To see how these filters were updated as a result of our analyses, see [gnomAD sample filters](#3.-Investigating-gnomAD-sample-filters) and the resulting gnomAD [minor release.](https://gnomad.broadinstitute.org/news/2021-10-gnomad-v3-1-2-minor-release/#improvements-to-the-hgdp--1kg-subset-release)\n",
    "\n",
    "**This script contains information on how to**:\n",
    "- Annotate new fields onto a Matrix Table from another Matrix Table or Hail Table\n",
    "- Unflatten a Hail Matrix Table\n",
    "- Harmonize datasets to prevent merge conflicts\n",
    "- Use plots to identify which gnomAD QC filters are removing populations entirely (`fail_n_snp_residual` used as an example)\n",
    "- Retrieve populations being unduly removed by filters (mostly AFR and OCE populations)\n",
    "- Filter Matrix Tables using a field within the Matrix Table\n",
    "- Filter samples using a hardcoded list of samples to remove\n",
    "- Plot certain fields from the Matrix Table:\n",
    "    - Number of SNPs\n",
    "    - Coverage\n",
    "    - Site Frequency \n",
    "    - Freemix\n",
    "    - Number of samples which failed a filter\n",
    "\n",
    "**Datasets merged are**:\n",
    "- sample_meta: sample metadata table which contains harmonized metadata for the HGDP_1kGP dataset\n",
    "- sample_qc_meta: gnomAD v3.1 sample qc metadata from for the hgdp_1kg subset which contains flags to denote which samples failed gnomAD QC filters\n",
    "- dense_mt: densified hgdp_1kg Matrix Table with a field of flags (mt.filters) to denote which variants passed or failed gnomAD qc filters\n",
    "\n",
    "Authors: Zan Koenig & Mary T. Yohannes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fd0022",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "\n",
    "# For renaming purposes\n",
    "import re\n",
    "\n",
    "# The import statements below allow for plotting in hail\n",
    "from hail.ggplot import *\n",
    "import plotly\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba907f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Data Management Function\n",
    "This function can be used to read in the HGDP+1kGP Matrix Table at different stages throughout the tutorial and allows the user to specify which filters they would like to apply to the dataset. This function helps to reduce the number of times intermediate data is written, decreasing the computational and monetary cost of running the tutorials.\n",
    "\n",
    "<br>\n",
    "<details><summary>Click <u><span style=\"color:blue\">here</span></u> for more information on the function arguments.</summary> \n",
    "    \n",
    "<br> \n",
    "Click on each argument name to learn more!\n",
    "\n",
    "<ul>    \n",
    "<li><details><summary><u>\n",
    "<span style=\"color:blue\">raw</span></u></summary>\n",
    "    \n",
    "<p>when <i><b>True</b></i>, will return a pre-QC Matrix Table</p></details></li>\n",
    "\n",
    "<li><details><summary><u>\n",
    "<span style=\"color:blue\">post_qc</span></u></summary> \n",
    "    \n",
    "<p>when <i><b>True</b></i>, will return a Matrix Table which has the following conducted:</p>\n",
    "<ul> \n",
    "    <li>sample_qc filtering</li>\n",
    "    <li>variant_qc filtering</li>\n",
    "    <li>outlier removal</li>\n",
    "    <li>duplicate removal</li>  \n",
    "    </ul></details></li>\n",
    "\n",
    "\n",
    "<li><details><summary><u>  \n",
    "<span style=\"color:blue\">sample_qc</span></u></summary>     \n",
    "    \n",
    "<p>When <i><b>True</b></i>, will return a Matrix Table with gnomAD's sample QC filters run on the dataset. For more information on gnomAD's sample QC steps click <a href=\"https://gnomad.broadinstitute.org/news/2020-10-gnomad-v3-1-new-content-methods-annotations-and-data-availability/#sample-qc-hard-filtering\"> here.</a></p></details></li>    \n",
    "    \n",
    "<li><details><summary><u>  \n",
    "<span style=\"color:blue\">variant_qc</span></u></summary>     \n",
    "    \n",
    "<p>When <i><b>True</b></i>, will return a Matrix Table with gnomAD's variant quality control filters run on the dataset. For more information on gnomAD's variant QC steps click <a href=\"https://gnomad.broadinstitute.org/news/2020-10-gnomad-v3-1-new-content-methods-annotations-and-data-availability/#variant-qc\"> here.</a></p></details></li>        \n",
    "\n",
    "<li><details><summary><u> \n",
    "<span style=\"color:blue\">duplicate</span></u></summary>     \n",
    "    \n",
    "<p>When <i><b>True</b></i>, will return a Matrix Table with any duplicates in the dataset removed. By default there are no duplicates in the dataset, but was included as it is a useful QC step to demonstrate</p></details></li> \n",
    "  \n",
    "<li><details><summary><u>\n",
    "<span style=\"color:blue\">outlier_removal</span></u></summary>     \n",
    "    \n",
    "<p>When <i><b>True</b></i>, will return a Matrix Table with pca outliers removed. These outliers were determined by running pc_relate. More information on how we created the outlier list can be found <a href=\"https://nbviewer.org/github/atgu/hgdp_tgp/blob/master/tutorials/nb4.ipynb#5.-Outlier-Removal\"> here.</a></p></details></li> \n",
    "\n",
    "</details> \n",
    "    \n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9aa0ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_qc(\n",
    "        raw: bool = False,\n",
    "        post_qc:bool = False,\n",
    "        sample_qc: bool = False,\n",
    "        variant_qc: bool = False,\n",
    "        outlier_removal: bool = False) -> hl.MatrixTable:\n",
    "    \"\"\"\n",
    "    Wrapper function to get HGDP+1kGP data as Matrix Table at different stages of QC/filtering.\n",
    "    By raw, returns pre QC MatrixTable with qc filters annotated but not filtered.\n",
    "\n",
    "    :param bool raw: if True, will return a preQC version of the dataset\n",
    "    :param bool post_qc: if True, will return a post QC Matrix Table that has gone through:\n",
    "        - sample QC\n",
    "        - variant QC\n",
    "        - outlier removal\n",
    "    :param bool sample_qc: if True, will return a post sample QC Matrix Table\n",
    "    :param bool variant_qc: if True, will return a post variant QC Matrix Table\n",
    "    :param bool outlier_removal: if True, will return a Matrix Table with PCA outliers removed\n",
    "    \"\"\"\n",
    "    # Reading in all the tables and Matrix Tables needed to generate the pre_qc Matrix Table\n",
    "    sample_meta = hl.import_table('gs://hgdp-1kg/hgdp_tgp/qc_and_figure_generation/gnomad_meta_v1.tsv')\n",
    "    sample_qc_meta = hl.read_table('gs://hgdp_tgp/output/gnomad_v3.1_sample_qc_metadata_hgdp_tgp_subset.ht')\n",
    "    dense_mt = hl.read_matrix_table(\n",
    "        'gs://gcp-public-data--gnomad/release/3.1.2/mt/genomes/gnomad.genomes.v3.1.2.hgdp_1kg_subset_dense.mt')\n",
    "    \n",
    "    # Running a Nai\n",
    "    dense_mt = dense_mt.naive_coalesce(5000)\n",
    "\n",
    "\n",
    "    # Takes a list of dicts and converts it to a struct format (works with nested structs too)\n",
    "    def dict_to_struct(d):\n",
    "        fields = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                v = dict_to_struct(v)\n",
    "            fields[k] = v\n",
    "        return hl.struct(**fields)\n",
    "\n",
    "    # Un-flattening a Hail Table with nested structure\n",
    "    # Dict to hold struct names as well as nested field names\n",
    "    d = {}\n",
    "\n",
    "    # Getting the row field names\n",
    "    row = sample_meta.row_value\n",
    "\n",
    "    # Returns a dict with the struct names as keys and their inner field names as values\n",
    "    for name in row:\n",
    "        def recur(dict_ref, split_name):\n",
    "            if len(split_name) == 1:\n",
    "                dict_ref[split_name[0]] = row[name]\n",
    "                return\n",
    "            existing = dict_ref.get(split_name[0])\n",
    "            if existing is not None:\n",
    "                assert isinstance(existing, dict), existing\n",
    "                recur(existing, split_name[1:])\n",
    "            else:\n",
    "                existing = {}\n",
    "                dict_ref[split_name[0]] = existing\n",
    "                recur(existing, split_name[1:])\n",
    "        recur(d, name.split('.'))\n",
    "\n",
    "    # Using the dict created from flattened struct, creating new structs now un-flattened\n",
    "    sample_meta = sample_meta.select(**dict_to_struct(d))\n",
    "    sample_meta = sample_meta.key_by('s')\n",
    "\n",
    "    # grabbing the columns needed from HGDP metadata\n",
    "    new_meta = sample_meta.select(sample_meta.hgdp_tgp_meta, sample_meta.bergstrom)\n",
    "\n",
    "    # Creating a table with gnomAD sample metadata and HGDP metadata\n",
    "    ht = sample_qc_meta.annotate(**new_meta[sample_qc_meta.s])\n",
    "\n",
    "    # Stripping 'v3.1::' from the names to match with the densified MT\n",
    "    ht = ht.key_by(s=ht.s.replace(\"v3.1::\", \"\"))\n",
    "\n",
    "    # Using hl.annotate_cols() method to annotate the gnomAD variant QC metadata onto the Matrix Table\n",
    "    mt = dense_mt.annotate_cols(**ht[dense_mt.s])\n",
    "    \n",
    "    if raw:\n",
    "        print(\"Returning default preQC Matrix Table\")\n",
    "        # returns preQC dataset\n",
    "        return mt\n",
    "    \n",
    "    if post_qc:\n",
    "        print(\"Returning post sample and variant QC Matrix Table with duplicates and PCA outliers removed\")\n",
    "        sample_qc = True\n",
    "        variant_qc = True\n",
    "        duplicate = True\n",
    "        outlier_removal = True\n",
    "    \n",
    "    if sample_qc:\n",
    "        print(\"Applying sample QC\")\n",
    "        # Apply sample QC filters to dataset\n",
    "        # Filtering samples to those who should pass gnomADs sample QC\n",
    "        # This filters to only samples that passed gnomAD sample QC hard filters\n",
    "        mt = mt.filter_cols(~mt.sample_filters.hard_filtered)\n",
    "\n",
    "    if variant_qc:\n",
    "        print(\"Applying variant QC\")\n",
    "        # Apply variant QC filters to dataset\n",
    "        # Subsetting the variants in the dataset to only PASS variants (those which passed gnomAD's variant QC)\n",
    "        # PASS variants are variants which have an entry in the filters field.\n",
    "        # This field contains an array which contains a bool if any variant qc filter was failed\n",
    "        # This is the last step in the QC process\n",
    "        mt = mt.filter_rows(hl.len(mt.filters) != 0, keep=False)\n",
    "\n",
    "    if outlier_removal:\n",
    "        print(\"Removing PCA outliers\")\n",
    "        # Remove PCA outliers\n",
    "        # Reading in the PCA outlier list\n",
    "        # To read in the PCA outlier list, first need to read the file in as a list\n",
    "        # Using hl.hadoop_open here which allows one to read in files into Hail from Google Cloud Storage\n",
    "        pca_outlier_path = 'gs://hgdp-1kg/hgdp_tgp/pca_outliers_v2.txt'\n",
    "        with hl.utils.hadoop_open(pca_outlier_path) as file:\n",
    "            outliers = [line.rstrip('\\n') for line in file]\n",
    "\n",
    "        # Using hl.literal here to convert the list from a python object to a Hail expression so that it can be used\n",
    "        # To filter out samples\n",
    "        outliers_list = hl.literal(outliers)\n",
    "\n",
    "        # Using the list of PCA outliers, using the ~ operator which is a negation operator and obtains the compliment\n",
    "        # In this case the compliment is samples which are not contained in the pca outlier list\n",
    "        mt = mt.filter_cols(~outliers_list.contains(mt['s']))\n",
    "        \n",
    "    # Calculating both variant and sample_qc metrics on the mt before returning\n",
    "    # So the stats are up to date with the version being written out\n",
    "    mt = hl.sample_qc(mt)\n",
    "    mt = hl.variant_qc(mt)\n",
    "\n",
    "    \n",
    "    return mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c2534",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Read in Datasets and Annotate\n",
    "<br>\n",
    "<details><summary>Click <u><span style=\"color:blue\">here</span></u> for more information about the input dataset.</summary>\n",
    "\n",
    "This input Matrix Table is a combination of 3 datasets: a harmonized sample metadata for the HGDP+1KG dataset, a gnomAD v3.1 sample qc metadata with samples that failed gnomAD QC filters flagged, and a densified HGDP+1KG Matrix Table.\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "<ul>\n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/impex.html#hail.methods.read_matrix_table\"> More on  <i> read_matrix_table() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.count\"> More on  <i> count() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/impex.html#hail.methods.read_table\"> More on  <i> read_table() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.annotate_rows\"> More on  <i> annotate_rows() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.expr.Expression.html#hail.expr.Expression.describe\"> More on  <i> describe() </i></a></li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf08e53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read-in the Matrix Table (shortened as mt)\n",
    "mt = apply_qc(default=True)\n",
    "\n",
    "# how many snps and samples are there? counts \n",
    "print('Num of snps and samples prior to any analysis = ' + str(mt.count())) # 211358784 snps & 4151 samples \n",
    "\n",
    "# get mt schema\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea10d07",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Investigating gnomAD sample filters\n",
    "\n",
    "<br>\n",
    "<details><summary>Click <u><span style=\"color:blue\">here</span></u> to learn why we are doing this.</summary>\n",
    "    \n",
    "9 out of the 28 gnomAD sample filters were dropping huge numbers of ancestrally diverse individuals (mostly African > (AFR) and Oceanian (OCE) populations). The filters use gnomADâ€™s principal component analysis (PCA) which is obtained from other samples to residualize the distribution of values from different populations and identify outliers. If there is an error and outliers are identified, the sample fails the filter. \n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "<ul>\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.filter_cols\"> More on  <i> filter_cols() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.expr.SetExpression.html#hail.expr.SetExpression.difference\"> More on  <i> difference() </i></a></li>\n",
    "\n",
    "<li><a href=\" https://hail.is/docs/0.2/hail.expr.CollectionExpression.html#hail.expr.CollectionExpression.length\"> More on  <i> length() </i></a></li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a856b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# put the gnomAD qc filters in a set \n",
    "all_sample_filters = set(mt['sample_filters']) \n",
    "\n",
    "# select out the filters that are removing whole populations despite them passing all other gnomAD filters\n",
    "# if a filter name starts with 'fail_', add it to a new set after removing 'fail_' from the name  \n",
    "bad_sample_filters = {re.sub('fail_', '', x) for x in all_sample_filters if x.startswith('fail_')} \n",
    "\n",
    "# filter out the samples that passed all gnomAD QC filters OR only failed the filters that were removing population wholly\n",
    "mt_filt = mt.filter_cols(mt['sample_filters']['qc_metrics_filters'].difference(bad_sample_filters).length() == 0)\n",
    "\n",
    "# how many samples were removed by the initial QC?\n",
    "print('Num of samples before initial QC = ' + str(mt.count()[1])) # 4151\n",
    "print('Num of samples after initial QC = ' + str(mt_filt.count()[1])) # 4120\n",
    "print('Samples removed = ' + str(mt.count()[1] - mt_filt.count()[1])) # 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f6358",
   "metadata": {},
   "source": [
    "# 4. Plotting results of gnomAD sample filter investigation\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a72248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mary to add additional information on this failed_filters_population_level file here\n",
    "filepath = \"gs://hgdp-1kg/hgdp_tgp/intermediate_files/failed_filters_population_level.csv\"\n",
    "filters = hl.import_table(filepath, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23dea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab only \"sample_filters.fail_n_snp_residual\"\n",
    "n_snp_resid = filters.annotate(population = filters['\"population\"'][1:hl.len(filters['\"population\"'])-1], \\\n",
    "                                   num_samples = hl.int(filters['\"num_of_samples\"']), \\\n",
    "                                   fail_n_snp_resid = hl.int(filters['\"sample_filters.fail_n_snp_residual\"']),\\\n",
    "                                 fail_gnomAD = hl.str(filters['\"failed_gnomAD\"']))\n",
    "\n",
    "#manipulate all strings to remove the extraneous quotation marks\n",
    "n_snp_resid = n_snp_resid.select(\"population\", \"num_samples\", \"fail_n_snp_resid\", \"fail_gnomAD\")\n",
    "\n",
    "# calculate the ratio between the number of samples that failed and the total number of samples in the population. \n",
    "n_snp_resid = n_snp_resid.annotate(fail_ratio = n_snp_resid.fail_n_snp_resid/n_snp_resid.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_snp_resid.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate scatter plots of ratios for each filter column across all populations colored by gnomAD failure \n",
    "plot_n_snp_resid = hl.ggplot.ggplot(n_snp_resid, hl.ggplot.aes(x=n_snp_resid.population, y=n_snp_resid.fail_ratio, \\\n",
    "                                                color=n_snp_resid.fail_gnomAD)) + \\\n",
    "    hl.ggplot.geom_point() +\\\n",
    "    hl.ggplot.ylab(\"Ratio of failed samples/total samples\") + \\\n",
    "    hl.ggplot.ggtitle(\"Failure of gnomAD n_snp_resids filter by population\")+\\\n",
    "    hl.ggplot.scale_x_discrete(breaks=list(range(78)))\n",
    "\n",
    "plot_n_snp_resid.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74c994",
   "metadata": {},
   "source": [
    "# 5. Pre-QC Plots\n",
    "When conducting quality control, it is often a good idea to create plots of things such as the number of SNPS and coverage, so that after removing samples or variants you get a visual representation of changes in the dataset and can potentially see if anything requires further investigation. \n",
    "\n",
    "The following plots show the dataset prior to running any sample QC filters.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c917af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict that maps color for plotting to region name for both pre and post QC plots\n",
    "newnames = {'AMR':\"#E41A1C\",'AFR':\"#984EA3\", 'OCE':\"#999999\", 'CSA':\"#FF7F00\", \n",
    "            'EAS':\"#4DAF4A\", 'EUR':\"#377EB8\", 'MID':\"#A65628\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08144a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using func to get pre_qc version of dataset\n",
    "pre_qc = apply_qc(raw=True)\n",
    "# As of Hail v. 0.2.82, ggplot only takes in tables as input\n",
    "# Making a table of samples for plotting\n",
    "pre_qc_col = pre_qc.cols()\n",
    "pre_qc_row = pre_qc.rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40c388",
   "metadata": {},
   "source": [
    "#### 5a. Number of SNPs - \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed623c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram of number of SNPS for each individual within each global region\n",
    "n_snp_pre_qc = hl.ggplot.ggplot(pre_qc_col, hl.ggplot.aes(x = pre_qc_col.sample_qc.n_snp)) + \\\n",
    "    hl.ggplot.geom_histogram(hl.ggplot.aes(fill = pre_qc_col.hgdp_tgp_meta.Genetic.region), min_val = 5000000, \n",
    "                             max_val = 7500000, bins = 200, position=\"identity\", alpha = .7) + \\\n",
    "    hl.ggplot.xlab(\"Number of SNPs\")+ \\\n",
    "    hl.ggplot.ggtitle(\"Number of SNPs, Pre-QC\")+ \\\n",
    "    hl.ggplot.coord_cartesian(ylim = (0,260))\n",
    "\n",
    "\n",
    "# Update colors\n",
    "n_snp_pre_qc = n_snp_pre_qc.to_plotly()\n",
    "\n",
    "n_snp_pre_qc.for_each_trace(\n",
    "    lambda trace: trace.update(marker=dict(color = newnames[trace.name]))\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "n_snp_pre_qc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0e9ae",
   "metadata": {},
   "source": [
    "#### 5b. Mean Coverage - \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fa785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a density plot of mean coverage per individual\n",
    "cov_pre_qc = hl.ggplot.ggplot(pre_qc_col, hl.ggplot.aes(x = pre_qc_col.bam_metrics.mean_coverage)) + \\\n",
    "    hl.ggplot.geom_density(hl.ggplot.aes(fill=pre_qc_col.project_meta.title),\n",
    "                             alpha = .7) + \\\n",
    "    hl.ggplot.xlab(\"Coverage (x)\")+ \\\n",
    "    hl.ggplot.ggtitle(\"Mean coverage, Pre-QC\")\n",
    "\n",
    "\n",
    "# Show plot\n",
    "cov_pre_qc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8789af",
   "metadata": {},
   "source": [
    "#### 5c. Freemix - \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aad088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting freemix colored by population \n",
    "freemix_pre_qc_pop = hl.ggplot.ggplot(pre_qc_col, hl.ggplot.aes(x = pre_qc_col.bam_metrics.freemix)) +\\\n",
    "    hl.ggplot.geom_histogram(hl.ggplot.aes(fill=pre_qc_col.hgdp_tgp_meta.Genetic.region), bins = 140) + \\\n",
    "    hl.ggplot.scale_y_log10(\"Count (log scale)\") +\\\n",
    "    hl.ggplot.xlab(\"Freemix\") + \\\n",
    "    hl.ggplot.ggtitle(\"Bam metrics: Freemix, Pre-QC\")+ \\\n",
    "    hl.ggplot.coord_cartesian(xlim = (0,.5))\n",
    "\n",
    "# #update legends\n",
    "# #update colors\n",
    "freemix_pre_qc_pop = freemix_pre_qc_pop.to_plotly()\n",
    "freemix_pre_qc_pop.for_each_trace(lambda trace: trace.update(marker=dict(color = newnames[trace.name])))\n",
    "\n",
    "#show plot\n",
    "freemix_pre_qc_pop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89562794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting freemix colored by project\n",
    "freemix_pre_qc_proj = hl.ggplot.ggplot(pre_qc_col, hl.ggplot.aes(x = pre_qc_col.bam_metrics.freemix)) +\\\n",
    "    hl.ggplot.geom_histogram(hl.ggplot.aes(fill=pre_qc_col.project_meta.title), position=\"identity\", bins = 140,\\\n",
    "                            alpha = .5) + \\\n",
    "    hl.ggplot.scale_y_log10(\"Count (log scale)\") +\\\n",
    "    hl.ggplot.xlab(\"Freemix\") + \\\n",
    "    hl.ggplot.ggtitle(\"Bam metrics: Freemix, Pre-QC\")+ \\\n",
    "    hl.ggplot.coord_cartesian(xlim = (0,.5))\n",
    "\n",
    "#show plot\n",
    "freemix_pre_qc_proj.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b2ee4",
   "metadata": {},
   "source": [
    "# 6. Post-QC Plots\n",
    "\n",
    "The following plots are the same as those made above with pre-qc data except now the dataset has gone through:\n",
    "- sample filtering\n",
    "- variant filtering\n",
    "- duplicate removal\n",
    "- PCA outlier removal\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in postQC Matrix Table\n",
    "post_qc = apply_qc(post_qc=True)\n",
    "\n",
    "# Making a table of samples for plotting\n",
    "post_qc_col = post_qc.cols()\n",
    "post_qc_row = post_qc.rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444cfc02",
   "metadata": {},
   "source": [
    "#### 6a. Number of SNPs - \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bad534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ggplot, differentiate between populations\n",
    "# Used to do fill by geographic region\n",
    "n_snp_post_qc = hl.ggplot.ggplot(post_qc_col, hl.ggplot.aes(x = post_qc_col.sample_qc.n_snp)) + \\\n",
    "    hl.ggplot.geom_histogram(hl.ggplot.aes(fill=post_qc_col.hgdp_tgp_meta.Genetic.region), min_val = 5000000, \n",
    "                             max_val = 7500000, bins = 200, position=\"identity\", alpha = .7) + \\\n",
    "    hl.ggplot.xlab(\"Number of SNPs\")+ \\\n",
    "    hl.ggplot.ggtitle(\"Number of SNPs, Post-QC\") + \\\n",
    "    hl.ggplot.coord_cartesian(ylim = (0,260)) \n",
    "\n",
    "\n",
    "# Update legends\n",
    "n_snp_post_qc = n_snp_post_qc.to_plotly()\n",
    "\n",
    "n_snp_post_qc.for_each_trace(\n",
    "    lambda trace: trace.update(marker=dict(color = newnames[trace.name]))\n",
    ")\n",
    "\n",
    "#show plot\n",
    "n_snp_post_qc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb93004",
   "metadata": {},
   "source": [
    "#### 6b. Mean Coverage - \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d91ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of mean coverage from bam_metrics\n",
    "# Separate by project (HGDP or 1kGP)\n",
    "cov_post_qc = hl.ggplot.ggplot(post_qc_col, hl.ggplot.aes(x = post_qc_col.bam_metrics.mean_coverage)) + \\\n",
    "    hl.ggplot.geom_density(hl.ggplot.aes(fill=post_qc_col.project_meta.title),\n",
    "                             alpha = .7) + \\\n",
    "    hl.ggplot.xlab(\"Coverage (x)\")+ \\\n",
    "    hl.ggplot.ggtitle(\"Mean coverage, Post-QC\")\n",
    "\n",
    "cov_post_qc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4567800",
   "metadata": {},
   "source": [
    "#### 6c. Freemix - \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e784b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "freemix_post_qc_pop = hl.ggplot.ggplot(post_qc_col, hl.ggplot.aes(x = post_qc_col.bam_metrics.freemix)) +\\\n",
    "    hl.ggplot.geom_histogram(hl.ggplot.aes(fill=post_qc_col.hgdp_tgp_meta.Genetic.region), bins = 70,\\\n",
    "                            alpha = 1) + \\\n",
    "    hl.ggplot.scale_y_log10(\"Count (log scale)\") +\\\n",
    "    hl.ggplot.xlab(\"Freemix\") + \\\n",
    "    hl.ggplot.ggtitle(\"Bam metrics: Freemix, Post-QC\")+ \\\n",
    "    hl.ggplot.coord_cartesian(xlim = (0,.5))\n",
    "\n",
    "#update legends\n",
    "freemix_post_qc_pop = freemix_post_qc_pop.to_plotly()\n",
    "freemix_post_qc_pop.for_each_trace(lambda trace: trace.update(marker=dict(color = newnames[trace.name])))\n",
    "\n",
    "#show plot\n",
    "freemix_post_qc_pop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freemix_post_qc_proj = hl.ggplot.ggplot(post_qc_col, hl.ggplot.aes(x = post_qc_col.bam_metrics.freemix)) +\\\n",
    "    hl.ggplot.geom_histogram(hl.ggplot.aes(fill=post_qc_col.project_meta.title), position=\"identity\", bins = 70,\\\n",
    "                            alpha = .5) + \\\n",
    "    hl.ggplot.scale_y_log10(\"Count (log scale)\") +\\\n",
    "    hl.ggplot.xlab(\"Freemix\") + \\\n",
    "    hl.ggplot.ggtitle(\"Bam metrics: Freemix, Post-QC\")+ \\\n",
    "    hl.ggplot.coord_cartesian(xlim = (0,.5))\n",
    "\n",
    "#show plot\n",
    "freemix_post_qc_proj.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d299b1",
   "metadata": {},
   "source": [
    "#### 6d. Site Frequency Spectrum -\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f646f72",
   "metadata": {},
   "source": [
    "Below is the code used to write out the file for site frequency spectrum plotting in order to cut down on runtime\n",
    "\n",
    "```python3 \n",
    "# Aggregating site frequency data for plotting\n",
    "sfs_data = ht_rows.aggregate(hl.agg.hist(post_qc.freq.AF[1], 0,1,250))\n",
    "with hl.hadoop_open('gs://hgdp-1kg/hgdp_tgp/qc_and_figure_generation/sfs_pre_qc.txt', 'w') as f:\n",
    "    f.write(str(dict(sfs_data)))\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14729418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "sfs_post_qc = hl.hadoop_open('gs://hgdp-1kg/hgdp_tgp/qc_and_figure_generation/sfs_post_qc.txt')\n",
    "sfs_dict = eval(sfs_post_qc.read())\n",
    "sfs_struct = hl.Struct(**sfs_dict)\n",
    "\n",
    "# Plot site frequency spectrum histogram\n",
    "sfs_p = hl.plot.histogram(sfs_struct, log = True, legend = \"Frequency of major allele at site\")\n",
    "show(sfs_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot this in ggplot as well, and I have included the code below. \n",
    "# But, there currently does not exist a way to directly use pre-aggregated data (which takes ~30 mins to compile)\n",
    "# Plotting this way takes the same amount of time and resources as running the cell above.\n",
    "p = hl.ggplot.ggplot(pre_qc_row, hl.ggplot.aes(x = pre_qc_row.freq.AF[1])) + \\\n",
    "    hl.ggplot.geom_histogram(bins = 200, position=\"identity\", alpha = .7) + \\\n",
    "    hl.ggplot.xlab(\"Allele frequency\")+ \\\n",
    "    hl.ggplot.ggtitle(\"Site Frequency Spectrum\") + \\\n",
    "    hl.ggplot.scale_y_log10(\"Number of loci (log scale)\")\n",
    "    \n",
    "p.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

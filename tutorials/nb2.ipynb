{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b073ca",
   "metadata": {},
   "source": [
    "## PCA and Ancestry Analyses\n",
    "\n",
    "Author: Mary T. Yohannes and Ally Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212736b",
   "metadata": {},
   "source": [
    "**To run this tutorial, you need to have started your cluster with `--packages-gnomad`.**\n",
    "\n",
    "*If you have not done this, you will need to shut down your current cluster and start a new one with the `--packages-gnomad` argument.* \n",
    "\n",
    "See the tutorials [README](https://github.com/atgu/hgdp_tgp/tree/master/tutorials#readme) for more information on how to start a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e78743",
   "metadata": {},
   "source": [
    "# Index\n",
    "1. [Set Default Paths](#1.-Set-Default-Paths)\n",
    "2. [Read in Pre-QC Dataset and Apply Quality Control Filters](#2.-Read-in-Pre-QC-Dataset-and-Apply-Quality-Control-Filters)\n",
    "3. [Variant Filtering and LD Pruning](#3.-Variant-Filtering-and-LD-Pruning)\n",
    "4. [Estimate Kinship using KING-robust](#4.-Estimate-Kinship-using-KING-robust)\n",
    "5. [Functions for PCA Analyses](#5.-Functions-for-PCA-Analyses)\n",
    "    1. [Run PCA on Unrelated Individuals](#5.a.-Run-PCA-on-Unrelated-Individuals)\n",
    "    2. [Project Related Individuals](#5.b.-Project-Related-Individuals)\n",
    "    3. [Plot Functions](#5.c.-Plot-Functions)\n",
    "6. [Run PCA with Outliers](#6.-Run-PCA-with-Outliers)\n",
    "    1. [Run Global PCA and Plot](#6.a.-Run-Global-PCA-and-Plot)\n",
    "    2. [Run Subcontinental PCA and Plot](#6.b.-Run-Subcontinental-PCA-and-Plot)\n",
    "7. [Outliers Removal](#7.-Outliers-Removal)\n",
    "8. [Rerun PCA Without Outliers](#8.-Rerun-PCA-Without-Outliers)\n",
    "    1. [Rerun Global PCA and Plot](#8.a.-Rerun-Global-PCA-and-Plot)\n",
    "    2. [Rerun Subcontinental PCA and Plot](#8.b.-Rerun-Subcontinental-PCA-and-Plot)\n",
    "9. [Writing out Matrix Tables](#9.-Write-Out-Matrix-Tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a11957",
   "metadata": {},
   "source": [
    "# General Overview \n",
    "The purpose of this notebook is to further filter the post-QC matrix table to prepare it for LD pruning, compute relatedness, and run Principal Component Analysis (PCA).\n",
    "\n",
    "**This script contains information on how to:**\n",
    "- Read in a matrix table (shortened as mt) and filter it using a field within the matrix table and a function imported from an external library\n",
    "- Run Hail common variant statistics and filter using allele frequency & call rate\n",
    "- Run LD pruning \n",
    "- Run relatedness and separate related and unrelated individuals\n",
    "- Set up functions to make redundant calculations concise\n",
    "- Calculate PC scores and project samples on to a PC space  \n",
    "- Run global and subcontinental PCA and plot them \n",
    "- Remove PCA outliers (filter using sample IDs)\n",
    "- Write out a matrix table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a3d7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"cb80db37-da82-4976-97f8-51edf7e5ae67\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"cb80db37-da82-4976-97f8-51edf7e5ae67\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"cb80db37-da82-4976-97f8-51edf7e5ae67\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"cb80db37-da82-4976-97f8-51edf7e5ae67\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"cb80db37-da82-4976-97f8-51edf7e5ae67\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"a7de8fba-5c74-42a3-8775-569cdb5babbf\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"a7de8fba-5c74-42a3-8775-569cdb5babbf\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"a7de8fba-5c74-42a3-8775-569cdb5babbf\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"a7de8fba-5c74-42a3-8775-569cdb5babbf\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"a7de8fba-5c74-42a3-8775-569cdb5babbf\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hail as hl\n",
    "\n",
    "# Functions from gnomAD library to apply genotype filters and project related samples  \n",
    "from gnomad.utils.filtering import filter_to_adj\n",
    "from gnomad.sample_qc.ancestry import pc_project\n",
    "\n",
    "# For plotting in Hail\n",
    "from hail.ggplot import *\n",
    "import plotly\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4246a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Hail \n",
    "hl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow output scrolling in Jupyter nb viewer for cells with long outputs \n",
    "\n",
    "from IPython.core.display import HTML\n",
    "css = open('format.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f403d",
   "metadata": {},
   "source": [
    "# 1. Set Default Paths\n",
    "\n",
    "These default paths can be edited by users as needed. It is recommended to run these tutorials without writing out datasets.\n",
    "\n",
    "**By default, all of the dataset write out sections are shown as markdown cells. If you would like to write out your own dataset, you can copy the code and paste it into a new code cell. Don't forget to change the paths in the following cell accordingly and edit the ```overwrite``` argument if you are writing out a dataset more than once.** \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88eec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for HGDP+1kGP dataset prior to applying gnomAD QC filters\n",
    "pre_qc_path = 'gs://gcp-public-data--gnomad/release/3.1.2/mt/genomes/gnomad.genomes.v3.1.2.hgdp_1kg_subset_dense.mt'\n",
    "\n",
    "# Path for gnomAD's HGDP+1kGP metadata for plotting \n",
    "metadata_path = 'gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg_v2/metadata_and_qc/gnomad_meta_updated.tsv'\n",
    "\n",
    "# Save the filtered and LD pruned mt as an intermediate file since LD pruning takes a while to rerun\n",
    "ld_pruned_path = 'gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg_v2/pca_preprocessing/ld_pruned.mt'\n",
    "\n",
    "# Hail table of related sample IDs for separating unrelateds and relateds for PCA run \n",
    "related_sample_ids_path = 'gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg_v2/pca_preprocessing/related_sample_ids.ht'\n",
    "\n",
    "# Path for with-outliers PCA results - global & subcontinental PCA \n",
    "pc_scores_with_outliers_path = 'gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg_v2/pca/pc_scores_with_outliers/'\n",
    "\n",
    "# PCA outliers file \n",
    "outliers_path = 'gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg_v2/pca/pca_outliers.txt'\n",
    "\n",
    "# Path for without-outliers PCA results - global & subcontinental PCA \n",
    "pc_scores_without_outliers_path = 'gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg_v2/pca/pc_scores_without_outliers/'\n",
    "\n",
    "# Paths for unrelated and related datasets without outliers   \n",
    "unrelateds_mt_without_outliers_path = 'gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg_v2/pca_results/unrelateds_without_outliers.mt'\n",
    "relateds_mt_without_outliers_path = 'gs://gcp-public-data--gnomad/release/3.1/secondary_analyses/hgdp_1kg_v2/pca_results/relateds_without_outliers.mt' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e5141",
   "metadata": {},
   "source": [
    "# 2. Read in Pre-QC Dataset and Apply Quality Control Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b5110",
   "metadata": {},
   "source": [
    "Since the post-QC mt was not written out, we run the same function as tutorial notebook 1 to apply the quality control filters to the pre-QC dataset.\n",
    "\n",
    "**To avoid errors, make sure to run the next two cells before running any code that includes the post-QC dataset.**\n",
    "\n",
    "<br>\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "<ul>\n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/impex.html#hail.methods.read_matrix_table\"> More on  <i> read_matrix_table() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.count\"> More on  <i> count() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html#hail.linalg.BlockMatrix.filter_cols\"> More on  <i> filter_cols() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html#hail.linalg.BlockMatrix.filter_rows\"> More on  <i> filter_rows() </i></a></li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19659ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function to:\n",
    "# apply gnomAD's sample, variant and genotype QC filters\n",
    "# remove two contaminated samples identified using CHARR - https://pubmed.ncbi.nlm.nih.gov/37425834/\n",
    "# remove the gnomAD sample that's added for QC purposes\n",
    "# only keep the variants which are found in the samples that are left \n",
    "# add gnomAD's HGDP+1kGP metadata with the updated population labels as a column field \n",
    "\n",
    "def run_qc(mt):\n",
    "    \n",
    "    ## Apply sample QC filters to dataset \n",
    "    # This filters to only samples that passed gnomAD's sample QC hard filters  \n",
    "    mt = mt.filter_cols(~mt.gnomad_sample_filters.hard_filtered) # removed 31 samples\n",
    "    \n",
    "    ## Apply variant QC filters to dataset\n",
    "    # This subsets to only PASS variants - those which passed gnomAD's variant QC\n",
    "    # PASS variants have an entry in the filters field \n",
    "    mt = mt.filter_rows(hl.len(mt.filters) != 0, keep=False)\n",
    "    \n",
    "    # Remove the two contaminated samples identified by CHARR and 'CHMI_CHMI3_WGS2'\n",
    "    contaminated_samples = {'HGDP01371', 'LP6005441-DNA_A09'}\n",
    "    contaminated_samples_list = hl.literal(contaminated_samples)\n",
    "    mt = mt.filter_cols(~contaminated_samples_list.contains(mt['s']))\n",
    "    \n",
    "    # CHMI_CHMI3_WGS2 is a sample added by gnomAD for QC purposes and has no metadata info \n",
    "    mt = mt.filter_cols(mt.s == 'CHMI_CHMI3_WGS2', keep = False)\n",
    "\n",
    "    # Only keep the variants which are found in the samples that are left \n",
    "    mt = mt.filter_rows(hl.agg.any(mt.GT.is_non_ref()))\n",
    "    \n",
    "    # Read in and add the metadata with the updated population labels as a column field \n",
    "    metadata = hl.import_table(metadata_path, impute = True, key = 's') \n",
    "    mt = mt.annotate_cols(meta_updated = metadata[mt.s])\n",
    "    \n",
    "    ## Apply genotype QC filters to the dataset\n",
    "    # This is done using a function imported from gnomAD and is the last step in the QC process\n",
    "    mt = filter_to_adj(mt)\n",
    "\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235d8b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 19:18:46.415 Hail: INFO: Reading table to impute column types 1) / 1]\n",
      "2023-12-17 19:18:51.744 Hail: INFO: Loading <StructExpression of type struct{s: str, `project_meta.sample_id`: str, `project_meta.research_project_key`: str, `project_meta.seq_project`: str, `project_meta.ccdg_alternate_sample_id`: str, `project_meta.ccdg_gender`: str, `project_meta.ccdg_center`: str, `project_meta.ccdg_study`: str, `project_meta.cram_path`: str, `project_meta.project_id`: str, `project_meta.v2_age`: str, `project_meta.v2_sex`: str, `project_meta.v2_hard_filters`: str, `project_meta.v2_perm_filters`: str, `project_meta.v2_pop_platform_filters`: str, `project_meta.v2_related`: str, `project_meta.v2_data_type`: str, `project_meta.v2_product`: str, `project_meta.v2_product_simplified`: str, `project_meta.v2_qc_platform`: str, `project_meta.v2_project_id`: str, `project_meta.v2_project_description`: str, `project_meta.v2_internal`: str, `project_meta.v2_investigator`: str, `project_meta.v2_known_pop`: str, `project_meta.v2_known_subpop`: str, `project_meta.v2_pop`: str, `project_meta.v2_subpop`: str, `project_meta.v2_neuro`: str, `project_meta.v2_control`: str, `project_meta.v2_topmed`: str, `project_meta.v2_high_quality`: str, `project_meta.v2_release`: bool, `project_meta.v2_pcr_free`: str, `project_meta.v2_project_name`: str, `project_meta.v2_release_2_0_2`: str, `project_meta.project_ancestry`: str, `project_meta.project_pop`: str, `project_meta.project_subpop`: str, `project_meta.pdo_owner`: str, `project_meta.category`: str, `project_meta.contact_pi`: str, `project_meta.sample_pi`: str, `project_meta.pm`: str, `project_meta.research_project`: str, `project_meta.pdo`: str, `project_meta.title`: str, `project_meta.product`: str, `project_meta.probably_releasable`: str, `project_meta.releasable`: bool, `project_meta.broad_external`: str, `project_meta.sex`: str, `project_meta.subpop_description`: str, `project_meta.exclude`: bool, `project_meta.exclude_reason`: str, `project_meta.case_control`: str, `project_meta.age`: str, `project_meta.age_bin`: str, `project_meta.tcga_tumor`: bool, `project_meta.age_alt`: str, `project_meta.v2_s_match`: str, `project_meta.topmed`: bool, `project_meta.neuro_cohort`: bool, `project_meta.neuro_case`: bool, `subsets.non_topmed`: bool, `subsets.controls_and_biobanks`: bool, `subsets.non_neuro`: bool, `subsets.non_v2`: bool, `subsets.non_cancer`: bool, `subsets.tgp`: bool, `subsets.hgdp`: bool, `bam_metrics.pct_bases_20x`: float64, `bam_metrics.pct_chimeras`: float64, `bam_metrics.freemix`: float64, `bam_metrics.mean_coverage`: float64, `bam_metrics.median_coverage`: int32, `bam_metrics.mean_insert_size`: float64, `bam_metrics.median_insert_size`: int32, `bam_metrics.pct_bases_10x`: float64, `sex_imputation.is_female`: bool, `sex_imputation.chr20_mean_dp`: float64, `sex_imputation.chrX_mean_dp`: float64, `sex_imputation.chrY_mean_dp`: float64, `sex_imputation.chrX_ploidy`: float64, `sex_imputation.chrY_ploidy`: float64, `sex_imputation.X_karyotype`: str, `sex_imputation.Y_karyotype`: str, `sex_imputation.sex_karyotype`: str, `sex_imputation.impute_sex_stats.f_stat`: float64, `sex_imputation.impute_sex_stats.n_called`: int32, `sex_imputation.impute_sex_stats.expected_homs`: int32, `sex_imputation.impute_sex_stats.observed_homs`: int32, `sample_qc.n_hom_ref`: int32, `sample_qc.n_het`: int32, `sample_qc.n_hom_var`: int32, `sample_qc.n_non_ref`: int32, `sample_qc.n_singleton`: int32, `sample_qc.n_snp`: int32, `sample_qc.n_insertion`: int32, `sample_qc.n_deletion`: int32, `sample_qc.n_transition`: int32, `sample_qc.n_transversion`: int32, `sample_qc.n_star`: int32, `sample_qc.r_ti_tv`: float64, `sample_qc.r_het_hom_var`: float64, `sample_qc.r_insertion_deletion`: float64, `sample_qc.n_snp_residual`: float64, `sample_qc.n_singleton_residual`: float64, `sample_qc.r_ti_tv_residual`: float64, `sample_qc.r_insertion_deletion_residual`: float64, `sample_qc.n_insertion_residual`: float64, `sample_qc.n_deletion_residual`: float64, `sample_qc.r_het_hom_var_residual`: float64, `sample_qc.n_transition_residual`: float64, `sample_qc.n_transversion_residual`: float64, `population_inference.training_pop`: str, `population_inference.pca_scores`: str, `population_inference.pop`: str, `population_inference.prob_afr`: float64, `population_inference.prob_ami`: float64, `population_inference.prob_amr`: float64, `population_inference.prob_asj`: float64, `population_inference.prob_eas`: float64, `population_inference.prob_fin`: float64, `population_inference.prob_mid`: float64, `population_inference.prob_nfe`: float64, `population_inference.prob_oth`: float64, `population_inference.prob_sas`: float64, `population_inference.training_pop_all`: str, `sample_filters.sex_aneuploidy`: bool, `sample_filters.insert_size`: bool, `sample_filters.chimera`: bool, `sample_filters.contamination`: bool, `sample_filters.bad_qc_metrics`: bool, `sample_filters.low_coverage`: bool, `sample_filters.ambiguous_sex`: bool, `sample_filters.failed_fingerprinting`: bool, `sample_filters.TCGA_tumor_sample`: bool, `sample_filters.hard_filters`: str, `sample_filters.hard_filtered`: bool, `sample_filters.release_related`: bool, `sample_filters.release_duplicate`: bool, `sample_filters.release_parent_child`: bool, `sample_filters.release_sibling`: bool, `sample_filters.all_samples_related`: bool, `sample_filters.all_samples_duplicate`: bool, `sample_filters.all_samples_parent_child`: bool, `sample_filters.all_samples_sibling`: bool, `sample_filters.fail_n_snp_residual`: bool, `sample_filters.fail_n_singleton_residual`: bool, `sample_filters.fail_r_ti_tv_residual`: bool, `sample_filters.fail_r_insertion_deletion_residual`: bool, `sample_filters.fail_n_insertion_residual`: bool, `sample_filters.fail_n_deletion_residual`: bool, `sample_filters.fail_r_het_hom_var_residual`: bool, `sample_filters.fail_n_transition_residual`: bool, `sample_filters.fail_n_transversion_residual`: bool, `sample_filters.qc_metrics_filters`: str, `relatedness_inference.relationships`: str, high_quality: bool, release: bool, `bergstrom.hgdp`: str, `bergstrom.lp`: str, `bergstrom.source`: str, `bergstrom.library_type`: str, `bergstrom.region`: str, `bergstrom.sex`: str, `bergstrom.coverage`: float64, `bergstrom.freemix`: float64, `bergstrom.capmq`: int32, `bergstrom.insert_size_average`: float64, `bergstrom.array_non_reference_discordance`: float64, `bergstrom.sample`: str, `hgdp_tgp_meta.Project`: str, `hgdp_tgp_meta.Study.region`: str, `hgdp_tgp_meta.Population`: str, `hgdp_tgp_meta.Genetic.region`: str, `hgdp_tgp_meta.Latitude`: float64, `hgdp_tgp_meta.Longitude`: float64, `hgdp_tgp_meta.Continent.colors`: str, `hgdp_tgp_meta.n`: int32, `hgdp_tgp_meta.rownum`: int32, `hgdp_tgp_meta.Pop.colors`: str, `hgdp_tgp_meta.Pop.shapes`: int32, sample_accession: str, source: str, library_type: str, population: str, latitude: float64, longitude: float64, region: str, sex: str, coverage: float64, freemix: float64, capmq: int32, insert_size_average: float64, array_non_reference_discordance: float64, library_alias_ENA: int32}> fields. Counts by type:\n",
      "  str: 86\n",
      "  float64: 46\n",
      "  bool: 44\n",
      "  int32: 22\n",
      "[Stage 3:==================================================>(49999 + 1) / 50000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of SNVs and samples after applying QC filters = (159339147, 4117)\n"
     ]
    }
   ],
   "source": [
    "# Read in the HGDP+1kGP pre-QC mt\n",
    "pre_qc_mt = hl.read_matrix_table(pre_qc_path)\n",
    "\n",
    "# Run QC \n",
    "post_qc_mt = run_qc(pre_qc_mt)\n",
    "\n",
    "# Validity check: number of variants and samples after applying QC filters\n",
    "# Took ~13min to print \n",
    "print('Num of SNVs and samples after applying QC filters = ' + str(post_qc_mt.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e0898",
   "metadata": {},
   "source": [
    "# 3. Variant Filtering and LD Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5075a1b",
   "metadata": {},
   "source": [
    "At this point, we have <code>159,339,147 SNVs</code>. We want fewer variants (~100-300k) for PCA for computational efficiency, so we apply filters on: allele frequency (<code>AF</code>) and missingness (<code>call rate</code>), and then run LD pruning.  \n",
    "\n",
    "Linkage disequilibrium (LD) is the correlation between nearby variants such that the alleles at neighboring polymorphisms (observed on the same chromosome) are associated within a population more often than if they were unlinked.    \n",
    "    \n",
    "For more information on LD pruning click <a href=\"https://www.nature.com/articles/nrg2361\"> here</a>.\n",
    "\n",
    "\n",
    "<br>\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "<ul>\n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/genetics.html#hail.methods.variant_qc\"> More on  <i> variant_qc() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/genetics.html#hail.methods.ld_prune\"> More on  <i> ld_prune() </i></a></li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a23bf9d",
   "metadata": {},
   "source": [
    "## 3a. Variant Filtering \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ee15c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:==================================================>(49999 + 1) / 50000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of variants after filtering = 5241811\n"
     ]
    }
   ],
   "source": [
    "# Run Hail's common variant statistics (QC metrics) \n",
    "var_qc_mt = hl.variant_qc(post_qc_mt) \n",
    "\n",
    "# Filter to variants with AF between 0.05 & 0.95, and call rate greater than 0.999    \n",
    "filtered_mt = var_qc_mt.filter_rows(((var_qc_mt.variant_qc.AF[0] > 0.05) & (var_qc_mt.variant_qc.AF[1] > 0.05)) &\n",
    "                                 ((var_qc_mt.variant_qc.AF[0] < 0.95) & (var_qc_mt.variant_qc.AF[1] < 0.95)) &\n",
    "                                 (var_qc_mt.variant_qc.call_rate > 0.999))\n",
    "# Took ~13min to print \n",
    "print('Num of variants after filtering = ' + str(filtered_mt.count()[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67102483",
   "metadata": {},
   "source": [
    "After filtering on allele frequency and call rate, the number of SNVs decreased from <code>159,339,147</code> to <code>5,241,811</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587e4b3",
   "metadata": {},
   "source": [
    "## 3b. LD Pruning\n",
    "\n",
    "We have too many variants for PCA that are also non-independent. We address this by pruning SNVs based on LD.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated variants \n",
    "# Took ~2hrs to run \n",
    "pruned_mt = hl.ld_prune(filtered_mt.GT, r2=0.1, bp_window_size=500000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd3c1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pruned_mt = filtered_mt.filter_rows(hl.is_defined(pruned_mt[filtered_mt.row_key])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d8b0646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of variants after LD pruning = 200403\n"
     ]
    }
   ],
   "source": [
    "# Took ~13min to print \n",
    "print('Num of variants after LD pruning = ' + str(filtered_pruned_mt.count()[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eebc46",
   "metadata": {},
   "source": [
    "Since the number of variants is now in the ~100-300k range, we proceed to the PCA analysis without any more adjustments.\n",
    "\n",
    "The LD pruning step takes a non-negligible amount of time to run, so to ensure that the downstream analyses steps don't take a long time, we write out an intermediate file. This write out step should take around 16 minutes to run.\n",
    "\n",
    "If the user wishes to export their own intermediate file, they can do so by changing the intermediate file path. Once a file has been written out, the <code>overwrite</code> argument can be used to replace it with a new file or keep the original one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f162d0",
   "metadata": {},
   "source": [
    "- Write out an intermediate file to speed up subsequent analyses (took ~16min to run)\n",
    "\n",
    "```python3\n",
    "filtered_pruned_mt.write(ld_pruned_path, overwrite=False) \n",
    "```\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043c4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the intermediate file back in for subsequent analyses\n",
    "filtered_pruned_mt = hl.read_matrix_table(ld_pruned_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df6f9d",
   "metadata": {},
   "source": [
    "# 4. Estimate Kinship using KING-robust\n",
    "\n",
    "When doing Principal Component Analysis (PCA), we need to separate the related and unrelated samples before computing the PC scores and plotting them. This is because if we compute PCA with the related samples in the dataset, the population structure and clustering will be affected by the relatedness that exists among those samples. Thus, we first have to estimate kinship using KING-robust (<code>hl.king</code> in Hail) to identify unrelated and related sets before running PCA. \n",
    "\n",
    "<br>  \n",
    "<details><summary>For more information on relatedness click <u><span style=\"color:blue\">here</span></u>.</summary>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4716688/\">Paper</a></li>\n",
    "        <li><a href=\"https://hail.is/docs/0.2/methods/relatedness.html#relatedness\">Hail documentation</a></li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "    <ul>\n",
    "        <li><a href=\"https://hail.is/docs/0.2/methods/relatedness.html#hail.methods.king\"> More on  <i> king() </i></a>\n",
    "        </li>\n",
    "        <li><a href=\"https://hail.is/docs/0.2/methods/misc.html#hail.methods.maximal_independent_set\"> More on  <i> maximal_independent_set() </i></a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec09a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took ~2hrs to run\n",
    "kinship = hl.king(filtered_pruned_mt.GT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fe7b1",
   "metadata": {},
   "source": [
    "- Write out an intermediate file to speed up subsequent analyses\n",
    "\n",
    "```python3\n",
    "kinship.write('gs://hgdp-1kg/tutorial_datasets/pca_preprocessing/kinship_king.mt', overwrite=False) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "541eaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the intermediate file back in for subsequent analyses\n",
    "kinship = hl.read_matrix_table('gs://hgdp-1kg/tutorial_datasets/pca_preprocessing/kinship_king.mt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the kinship mt into a table with three columns \n",
    "# Exclude pairs of samples with kinship lower than 0.05 \n",
    "relatedness_ht = kinship.filter_entries((kinship.s_1 != kinship.s) & (kinship.phi >= 0.05)).entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac174a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify closely related individuals in pairs (list of sample IDs) using maximal independent set \n",
    "related_sample_ids = hl.maximal_independent_set(relatedness_ht.s_1, relatedness_ht.s, False) # 698 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26140da6",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Write out sample IDs of related individuals  \n",
    "\n",
    "```python3\n",
    "related_sample_ids.write(related_sample_ids_path, overwrite=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdff37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of related sample IDs back in\n",
    "related_sample_ids = hl.read_table(related_sample_ids_path)\n",
    "\n",
    "# Subset the filtered and pruned mt to unrelated samples only \n",
    "# Sample IDs that are NOT present in the list of related individuals  \n",
    "unrelateds_mt_preoutlier = filtered_pruned_mt.filter_cols(hl.is_defined(related_sample_ids[filtered_pruned_mt.col_key]), keep=False) \n",
    "\n",
    "# Do the same as above but this time subset to related samples only \n",
    "# Sample IDs that are present in the list of related individuals    \n",
    "relateds_mt_preoutlier = filtered_pruned_mt.filter_cols(hl.is_defined(related_sample_ids[filtered_pruned_mt.col_key]), keep=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6032dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of SNVs and samples for unrelateds = (200403, 3419)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:=============================>                             (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of SNVs and samples for relateds = (200403, 698)\n"
     ]
    }
   ],
   "source": [
    "# Print SNV and sample counts for each mt \n",
    "\n",
    "print('Num of SNVs and samples for unrelateds = ' + str(unrelateds_mt_preoutlier.count())) # (200403, 3419) \n",
    "print('Num of SNVs and samples for relateds = ' + str(relateds_mt_preoutlier.count())) # (200403, 698)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edf23d",
   "metadata": {},
   "source": [
    "# 5. Functions for PCA Analyses\n",
    "\n",
    "PCA is run on the unrelated samples first. Then, the related samples are projected onto the PC space of the unrelated samples to get their PC scores. This way the population structure and clustering is not affected by the relatedness among samples.  \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0a36d9",
   "metadata": {},
   "source": [
    "## 5.a. Run PCA on Unrelated Individuals\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f08c372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca(mt: hl.MatrixTable):\n",
    "    \"\"\"\n",
    "    Runs PCA on a dataset\n",
    "    :param mt: dataset to run PCA on\n",
    "    :return: loadings and pc scores of unrelated samples \n",
    "    \"\"\"\n",
    "    pca_evals, pca_scores, pca_loadings = hl.hwe_normalized_pca(mt.GT, k=20, compute_loadings=True)\n",
    "    pca_mt = mt.annotate_rows(pca_af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2)\n",
    "    pca_loadings = pca_loadings.annotate(pca_af=pca_mt.rows()[pca_loadings.key].pca_af)\n",
    "    pca_scores = pca_scores.transmute(**{f'PC{i}': pca_scores.scores[i - 1] for i in range(1, 21)})\n",
    "    \n",
    "    return pca_loadings, pca_scores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c703e0",
   "metadata": {},
   "source": [
    "## 5.b. Project Related Individuals\n",
    "\n",
    "**If running the cell below results in an error, double check that you used the  `--packages gnomad` argument when starting your cluster.**  \n",
    "- See the tutorials [README](https://github.com/atgu/hgdp_tgp/tree/master/tutorials#readme) for more information on how to start a cluster.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab2dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_individuals(project_mt, pca_loadings, unrel_scores, out_path: str, reg_name:str, outlier_status:str):\n",
    "    \"\"\"\n",
    "    Project samples into predefined PCA space\n",
    "    :param project_mt: matrix table of related samples to project \n",
    "    :param pca_loadings: existing PCA space of unrelated samples \n",
    "    :param unrel_scores: unrelated samples' PC scores\n",
    "    :param out_path: path for where to save PCA projection outputs\n",
    "    :param reg_name: region name for saving output purposes\n",
    "    :param outlier_status: is the dataset with or without outliers? \n",
    "    \"\"\"\n",
    "    ht_projections = pc_project(project_mt, pca_loadings)  \n",
    "    ht_projections = ht_projections.transmute(**{f'PC{i}': ht_projections.scores[i - 1] for i in range(1, 21)}) \n",
    "    scores = unrel_scores.union(ht_projections) # combine the pc scores from both the unrelateds and relateds \n",
    "    scores.export(out_path + reg_name + '_scores_' + outlier_status + '.txt.bgz') # write output for plotting    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd1f6a",
   "metadata": {},
   "source": [
    "## 5.c. Plot Functions\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84cf27f",
   "metadata": {},
   "source": [
    "### Global PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "752a3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_global_pca(scores_path, outlier_status):\n",
    "    \"\"\"\n",
    "    :param scores_path: general path where PC score files are located \n",
    "    :param outlier_status: are outlier samples present in the scores file (use \"with_outliers\" OR \"without_outliers\")\n",
    "    \"\"\"\n",
    "    # Dictionary mapping colors to region names \n",
    "    cont_colors = {'AMR':\"#E41A1C\",\n",
    "               'AFR':\"#984EA3\", \n",
    "               'OCE':\"#999999\",\n",
    "               'CSA':\"#FF7F00\",\n",
    "               'EAS':\"#4DAF4A\", \n",
    "               'EUR':\"#377EB8\", \n",
    "               'MID':\"#A65628\" }\n",
    "    \n",
    "    # Import global PC scores table \n",
    "    global_scores = hl.import_table(scores_path + 'GLOBAL_scores_' + outlier_status + '.txt.bgz', impute = True)\n",
    "\n",
    "    # Add information from the metadata for plotting purposes \n",
    "    global_scores = global_scores.annotate(\n",
    "        global_pop = metadata[global_scores.s]['hgdp_tgp_meta.Genetic.region'], \n",
    "        subpop = metadata[global_scores.s]['population'],\n",
    "        global_color = metadata[global_scores.s]['hgdp_tgp_meta.Continent.colors'],\n",
    "        subpop_color = metadata[global_scores.s]['hgdp_tgp_meta.Pop.colors'],\n",
    "        subpop_shapes = metadata[global_scores.s]['hgdp_tgp_meta.Pop.shapes'],\n",
    "        proj_title = metadata[global_scores.s]['hgdp_tgp_meta.Project'])\n",
    "\n",
    "    # Make plot\n",
    "    # Only plotting PC1 vs PC2 here but you can change the PC values OR make a for loop to plot the rest of the PCs\n",
    "    p = ggplot(global_scores, aes(x = global_scores.PC1, y = global_scores.PC2))+ \\\n",
    "        geom_point(aes(color = global_scores.global_pop,\n",
    "                       shape = global_scores.proj_title),\n",
    "                       size = 3, alpha = .5) +\\\n",
    "        xlab(\"PC1\") + \\\n",
    "        ylab(\"PC2\") + \\\n",
    "        ggtitle(\"Global PCA \" + outlier_status.replace('_', ' '))+\\\n",
    "        labs(shape = 'Project', color = 'Population') +\\\n",
    "        scale_color_manual(values=cont_colors)\n",
    "\n",
    "    return p "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c06e1",
   "metadata": {},
   "source": [
    "### Subcontinental PCA\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7c44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subcont_pca(scores_path, outlier_status):\n",
    "    \"\"\"\n",
    "    :param scores_path: general path where PC score files are located  \n",
    "    :param outlier_status: are outlier samples present in the scores file (use \"with_outliers\" OR \"without_outliers\")   \n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to save the subcontinental PCA plots by their respective regions \n",
    "    pca_plots = {}\n",
    "\n",
    "    # Loop through each subcontinental region \n",
    "    regions = ['AFR', 'AMR', 'CSA', 'EAS', 'EUR', 'MID', 'OCE']\n",
    " \n",
    "    for region in regions:\n",
    "        # Import PC scores table \n",
    "        subcont_scores = hl.import_table(scores_path + region + '_scores_' + outlier_status + '.txt.bgz', impute = True)\n",
    "\n",
    "        # Add information from the metadata for plotting purposes \n",
    "        subcont_scores = subcont_scores.annotate(\n",
    "            global_pop = metadata[subcont_scores.s]['hgdp_tgp_meta.Genetic.region'], \n",
    "            subpop = metadata[subcont_scores.s]['population'],\n",
    "            global_color = metadata[subcont_scores.s]['hgdp_tgp_meta.Continent.colors'],\n",
    "            subpop_color = metadata[subcont_scores.s]['hgdp_tgp_meta.Pop.colors'],\n",
    "            subpop_shapes = metadata[subcont_scores.s]['hgdp_tgp_meta.Pop.shapes'],\n",
    "            proj_title = metadata[subcont_scores.s]['hgdp_tgp_meta.Project'])\n",
    "\n",
    "        # Make plot \n",
    "        # Only plotting PC1 vs PC2 here but you can change the PC values OR make a for loop to plot the rest of the PCs\n",
    "        p = ggplot(subcont_scores, aes(x=subcont_scores.PC1, y=subcont_scores.PC2)) + \\\n",
    "            geom_point(aes(color = subcont_scores.subpop, \n",
    "                           shape = subcont_scores.proj_title),\n",
    "                           size = 3, alpha = .3) +\\\n",
    "            xlab(\"PC1\") + \\\n",
    "            ylab(\"PC2\") + \\\n",
    "            ggtitle(region + \" PCA \" + outlier_status.replace('_', ' '))+\\\n",
    "            labs(shape = 'Project', color = 'Population')\n",
    "\n",
    "        # Add plot to dictionary with the region name as its key \n",
    "        pca_plots[region] = p\n",
    "\n",
    "    return pca_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe884bf",
   "metadata": {},
   "source": [
    "# 6. Run PCA with Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab3b82",
   "metadata": {},
   "source": [
    "In this section, we calculate PCA globally and subcontinentally, and plot the results using the functions written in section 5 above **so make sure all functions are run beforehand**. The following PCA plots are prior to the removal of any outliers.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in gnomAD's HGDP+1kGP metadata for plot annotation\n",
    "metadata = hl.import_table(metadata_path, impute = True, key = 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e6e604",
   "metadata": {},
   "source": [
    "## 6.a. Run Global PCA and Plot\n",
    "\n",
    "We are doing this to see the population structure and clustering on a continental level and contextualize the data globally.    \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PC scores \n",
    "\n",
    "# This block took ~1hr to run \n",
    "\n",
    "# Dictionaries to hold unrelateds' PCA loadings and scores\n",
    "loadings_dict = {}\n",
    "unrel_scores_dict = {}\n",
    "\n",
    "# Run PCA on unrelated samples as a whole\n",
    "loadings_dict['GLOBAL'], unrel_scores_dict['GLOBAL'] = run_pca(unrelateds_mt_preoutlier)  \n",
    "\n",
    "# Project related samples onto unrelated-samples' PC space \n",
    "project_individuals(relateds_mt_preoutlier, loadings_dict['GLOBAL'], unrel_scores_dict['GLOBAL'], pc_scores_with_outliers_path, 'GLOBAL', 'with_outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA \n",
    "global_with_outliers = plot_global_pca(pc_scores_with_outliers_path, \"with_outliers\") \n",
    "\n",
    "# Show PC1 Vs PC2\n",
    "global_with_outliers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42f9fd",
   "metadata": {},
   "source": [
    "## 6.b. Run Subcontinental PCA and Plot\n",
    "\n",
    "We are doing this to see the population structure and clustering on a subcontinental level, and contextualize data within continental regions. This helped us identify outliers which are removed later on.     \n",
    "\n",
    "**When running the following code cell, the notebook might freeze/throw an error after running PCA for 3-4 regions. Thus, we run it in groups of 3-4 regions at a time. If you want to run subcontinental PCA, we recommend doing that.**\n",
    "\n",
    "<br>\n",
    "\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "\n",
    "<ul>\n",
    "<li><a href=\"more info https://hail.is/docs/0.2/methods/genetics.html#hail.methods.hwe_normalized_pca\"> More on <i> hwe_normalized_pca() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.annotate_rows\"> More on <i> annotate_rows() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.annotate\"> More on <i> annotate() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.transmute\"> More on <i> transmute() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.export\"> More on <i> export() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/experimental/index.html#hail.experimental.pc_project\"> More on <i> pc_project() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.expr.Expression.html#hail.expr.Expression.collect\"> More on <i> collect() </i></a></li>\n",
    "</ul>\n",
    "    \n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c0304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PC scores \n",
    "\n",
    "# Run time breakdown for this cell is as follows:\n",
    "# 1hr & 42 min for EAS, AMR, CSA\n",
    "# 1hr & 23 min for EUR, AFR and OCE\n",
    "# 34 min for MID\n",
    "\n",
    "# Dictionaries to hold unrelateds' PCA loadings and scores\n",
    "loadings_dict = {}\n",
    "unrel_scores_dict = {}\n",
    "regions = unrelateds_mt_preoutlier['hgdp_tgp_meta']['genetic_region'].collect() \n",
    "regions = list(dict.fromkeys(regions)) # convert into a list\n",
    "# There are 7 regions: EUR, AFR, AMR, EAS, CSA, OCE, and MID\n",
    "\n",
    "# For each region, run PCA on the unrelated samples \n",
    "for i in regions:  \n",
    "    if i is not None: # exclude a none value\n",
    "        # Filter the unrelateds per region\n",
    "        subcont_unrelateds = unrelateds_mt_preoutlier.filter_cols(unrelateds_mt_preoutlier['hgdp_tgp_meta']['genetic_region'] == i) \n",
    "\n",
    "        # Run PCA\n",
    "        loadings_dict[i], unrel_scores_dict[i] = run_pca(subcont_unrelateds)\n",
    "\n",
    "        # Filter the related mt per region \n",
    "        subcont_relateds = relateds_mt_preoutlier.filter_cols(relateds_mt_preoutlier['hgdp_tgp_meta']['genetic_region'] == i)  \n",
    "\n",
    "        # Project related samples onto unrelated-samples' PC space \n",
    "        project_individuals(subcont_relateds, loadings_dict[i], unrel_scores_dict[i], pc_scores_with_outliers_path, i, 'with_outliers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a784734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA\n",
    "subcont_with_outliers = plot_subcont_pca(pc_scores_with_outliers_path, \"with_outliers\") \n",
    "\n",
    "# Show subcontinental PC1 Vs PC2 plots one by one \n",
    "for region in ['AFR', 'AMR', 'CSA', 'EAS', 'EUR', 'MID', 'OCE']:\n",
    "    subcont_with_outliers[region].show()\n",
    "    \n",
    "# If you are only interested in one subcontinental region, you can do the following. Using AFR as an example:\n",
    "subcont_with_outliers[\"AFR\"].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456f423",
   "metadata": {},
   "source": [
    "# 7. Outliers Removal\n",
    "\n",
    "After [plotting the PCs](https://github.com/atgu/hgdp_tgp/blob/master/plot_pca.Rmd) using R, 23 outliers were identified. \n",
    "\n",
    "[Back to Index](#Index)\n",
    "\n",
    "| sample ID | Genetic region | Population |\n",
    "| --- | --- | --- |\n",
    "| HG01880 | AFR | ACB |\n",
    "| HG01881 | AFR | ACB |\n",
    "| NA20274 | AFR | ASW |\n",
    "| NA20299 | AFR | ASW |\n",
    "| NA20314 | AFR | ASW |\n",
    "| HGDP00013 | CSA | Brahui |\n",
    "| HGDP00029 | CSA | Brahui |\n",
    "| HGDP00057 | CSA | Balochi |\n",
    "| HGDP00130 | CSA | Makrani |\n",
    "| HGDP00150 | CSA | Makrani |\n",
    "| HGDP00175 | CSA | Sindhi |\n",
    "| HGDP01298 | EAS | Uygur |\n",
    "| HGDP01300 | EAS | Uygur |\n",
    "| HGDP01303 | EAS | Uygur |\n",
    "| LP6005443-DNA_B02 | EAS | Uygur |\n",
    "| HG01628 | EUR | IBS | \n",
    "| HG01629 | EUR | IBS | \n",
    "| HG01630 | EUR | IBS | \n",
    "| HG01694 | EUR | IBS | \n",
    "| HG01696 | EUR | IBS |\n",
    "| HGDP00621 | MID | Bedouin |\n",
    "| HGDP01270 | MID | Mozabite |\n",
    "| HGDP01271 | MID | Mozabite |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30136453",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "    \n",
    "- <a href=\"more info https://hail.is/docs/0.2/utils/index.html#hail.utils.hadoop_open\"> More on  <i> hl.utils.hadoop_open() </i></a>\n",
    "    \n",
    "- <a href=\"more info https://hail.is/docs/0.2/functions/core.html#hail.expr.functions.literal\"> More on  <i> hl.literal() </i></a>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86fe5f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before outlier removal: 4117\n",
      "After outlier removal: 4094\n",
      "Total samples removed: 23\n"
     ]
    }
   ],
   "source": [
    "# Read in the filtered and pruned dataset if not already done so \n",
    "filtered_pruned_mt = hl.read_matrix_table(ld_pruned_path)\n",
    "\n",
    "# Read in the PCA outliers file into a list\n",
    "with hl.utils.hadoop_open(outliers_path) as file: \n",
    "    outliers = [line.rstrip('\\n') for line in file]\n",
    "    \n",
    "# Capture and broadcast the list as an expression\n",
    "outliers_list = hl.literal(outliers)\n",
    "\n",
    "# Remove the 23 outliers from the pruned dataset \n",
    "mt_without_outliers = filtered_pruned_mt.filter_cols(~outliers_list.contains(filtered_pruned_mt['s']))\n",
    "\n",
    "# Validity check \n",
    "print('Before outlier removal: ' + str(filtered_pruned_mt.count()[1]))\n",
    "print('After outlier removal: ' + str(mt_without_outliers.count()[1])) \n",
    "num_outliers = filtered_pruned_mt.count()[1] - mt_without_outliers.count()[1]\n",
    "print('Total samples removed: ' + str(num_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933ef2d",
   "metadata": {},
   "source": [
    "# 8. Rerun PCA Without Outliers\n",
    "\n",
    "**Before running this section, make sure to run all functions in section 5 above.**\n",
    "\n",
    "Here we are using the dataset without outliers and set new paths for the outputs.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c69ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:====================================>                      (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400 694\n"
     ]
    }
   ],
   "source": [
    "# Read the list of related-sample IDs back in\n",
    "related_sample_ids = hl.read_table(related_sample_ids_path)\n",
    "\n",
    "# Divide the new dataset [one without the 23 outliers] to unrelated and related samples \n",
    "unrelateds_without_outliers = mt_without_outliers.filter_cols(hl.is_defined(related_sample_ids[mt_without_outliers.col_key]), keep=False) \n",
    "relateds_without_outliers = mt_without_outliers.filter_cols(hl.is_defined(related_sample_ids[mt_without_outliers.col_key]), keep=True)\n",
    "\n",
    "# Validity check \n",
    "print(unrelateds_without_outliers.count()[1], relateds_without_outliers.count()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d11d23",
   "metadata": {},
   "source": [
    "## 8.a. Rerun Global PCA and Plot\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PC scores \n",
    "\n",
    "# This cell took 20 min to run\n",
    "\n",
    "# Dictionaries to hold unrelateds' PCA loadings and scores\n",
    "loadings_dict = {}\n",
    "unrel_scores_dict = {}\n",
    "\n",
    "# Run PCA on unrelated samples as a whole  \n",
    "loadings_dict['GLOBAL'], unrel_scores_dict['GLOBAL'] = run_pca(unrelateds_without_outliers)  \n",
    "\n",
    "# Project related samples onto unrelated-samples' PC space \n",
    "project_individuals(relateds_without_outliers, loadings_dict['GLOBAL'], unrel_scores_dict['GLOBAL'], pc_scores_without_outliers_path, 'GLOBAL', 'without_outliers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c347fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA \n",
    "global_without_outliers = plot_global_pca(pc_scores_without_outliers_path, \"without_outliers\") \n",
    "\n",
    "# Show PC1 Vs PC2\n",
    "global_without_outliers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682eff2b",
   "metadata": {},
   "source": [
    "## 8.b. Rerun Subcontinental PCA and Plot\n",
    "\n",
    "**When running the following code cell, the notebook might freeze/throw an error after running PCA for 3-4 regions. Thus, we run it in groups of 3-4 regions at a time. If you want to run subcontinental PCA, we recommend doing that.**\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<details><summary>For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "\n",
    "<ul>\n",
    "<li><a href=\"more info https://hail.is/docs/0.2/methods/genetics.html#hail.methods.hwe_normalized_pca\"> More on <i> hwe_normalized_pca() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.annotate_rows\"> More on <i> annotate_rows() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.annotate\"> More on <i> annotate() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.transmute\"> More on <i> transmute() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.export\"> More on <i> export() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/experimental/index.html#hail.experimental.pc_project\"> More on <i> pc_project() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.expr.Expression.html#hail.expr.Expression.collect\"> More on <i> collect() </i></a></li>\n",
    "    </ul>\n",
    "    \n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38cf6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PC scores \n",
    "\n",
    "# Run time breakdown for this cell is as follows:\n",
    "# 1hr & 40min for EAS, AMR, CSA, OCE\n",
    "# 1hr & 42min for EUR, AFR, MID\n",
    "\n",
    "# Dictionaries to hold unrelateds' PCA loadings and scores  \n",
    "loadings_dict = {}\n",
    "unrel_scores_dict = {}\n",
    "regions = mt_without_outliers['hgdp_tgp_meta']['genetic_region'].collect() \n",
    "regions = list(dict.fromkeys(regions)) # convert into a list\n",
    "# There are 7 regions: EUR, AFR, AMR, EAS, CSA, OCE, and MID\n",
    "\n",
    "# For each region, run PCA on the unrelated samples \n",
    "for i in regions:  \n",
    "    if i is not None: # exclude a none value\n",
    "        # Filter the unrelateds per region\n",
    "        subcont_unrelateds = unrelateds_without_outliers.filter_cols(unrelateds_without_outliers['hgdp_tgp_meta']['genetic_region'] == i) \n",
    "\n",
    "        # Run PCA\n",
    "        loadings_dict[i], unrel_scores_dict[i] = run_pca(subcont_unrelateds)\n",
    "\n",
    "        # Filter the related mt per region \n",
    "        subcont_relateds = relateds_without_outliers.filter_cols(relateds_without_outliers['hgdp_tgp_meta']['genetic_region'] == i)  \n",
    "\n",
    "        # Project related samples onto unrelated-samples' PC space \n",
    "        project_individuals(subcont_relateds, loadings_dict[i], unrel_scores_dict[i], pc_scores_without_outliers_path, i, 'without_outliers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA\n",
    "subcont_without_outliers = plot_subcont_pca(pc_scores_without_outliers_path, \"without_outliers\") \n",
    "\n",
    "# Show subcontinental PC1 Vs PC2 plots one by one \n",
    "for region in ['AFR', 'AMR', 'CSA', 'EAS', 'EUR', 'MID', 'OCE']:\n",
    "    subcont_without_outliers[region].show()\n",
    "    \n",
    "# If you are only interested in one subcontinental region, you can do the following. Using AFR as an example:\n",
    "subcont_without_outliers[\"AFR\"].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe82db",
   "metadata": {},
   "source": [
    "# 9. Write Out Matrix Tables \n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d86b1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- Separately write out mts of unrelated and related samples without outliers - 10min to run \n",
    "\n",
    "``` python3\n",
    "# Unrelated mt\n",
    "unrelateds_without_outliers.write(unrelateds_mt_without_outliers_path, overwrite=False)\n",
    "\n",
    "# Related mt\n",
    "relateds_without_outliers.write(relateds_mt_without_outliers_path, overwrite=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a2f781",
   "metadata": {},
   "source": [
    "### NOTE: The PCA plots shown above can also be easily plotted in R with better resolution. Click [here](https://github.com/atgu/hgdp_tgp/blob/master/figure_generation/plot_pca.Rmd) for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a32c46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"Thread-39\" java.lang.NullPointerException97 + 176) / 50000]\n",
      "\tat sparkmonitor.listener.JupyterSparkMonitorListener$TaskUpdaterThread.$anonfun$run$1(CustomListener.scala:116)\n",
      "\tat scala.collection.TraversableLike$grouper$1$.apply(TraversableLike.scala:465)\n",
      "\tat scala.collection.TraversableLike$grouper$1$.apply(TraversableLike.scala:455)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableLike.groupBy(TraversableLike.scala:524)\n",
      "\tat scala.collection.TraversableLike.groupBy$(TraversableLike.scala:454)\n",
      "\tat scala.collection.AbstractTraversable.groupBy(Traversable.scala:108)\n",
      "\tat sparkmonitor.listener.JupyterSparkMonitorListener$TaskUpdaterThread.run(CustomListener.scala:116)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "[Stage 3:==================================================>(49999 + 2) / 50000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153894851, 4094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:==================================================>(49999 + 2) / 50000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153894851, 4094)\n"
     ]
    }
   ],
   "source": [
    "# Sample and variant count after removing PCA outliers from the post-QC mt (before variant filtering and LD pruning)\n",
    "\n",
    "# Read in the PCA outliers file into a list\n",
    "with hl.utils.hadoop_open(outliers_path) as file: \n",
    "    outliers = [line.rstrip('\\n') for line in file]\n",
    "    \n",
    "# Capture and broadcast the list as an expression\n",
    "outliers_list = hl.literal(outliers)\n",
    "\n",
    "# Remove the 23 outliers from the post-QC mt dataset \n",
    "post_qc_mt_without_outliers = post_qc_mt.filter_cols(~outliers_list.contains(post_qc_mt['s']))\n",
    "\n",
    "# Only keep the variants which are found in the samples that are left \n",
    "p_o_mt = post_qc_mt_without_outliers.filter_rows(hl.agg.any(post_qc_mt_without_outliers.GT.is_non_ref()))\n",
    "\n",
    "print(p_o_mt.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98bf6db",
   "metadata": {},
   "source": [
    "[Back to Index](#Index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

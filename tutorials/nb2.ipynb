{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7258239",
   "metadata": {},
   "source": [
    "## PCA and Ancestry Analyses\n",
    "\n",
    "Author: Mary T. Yohannes and Ally Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8132b",
   "metadata": {},
   "source": [
    "**To run this tutorial, you need to have started your cluster with `--packages-gnomad`.**\n",
    "\n",
    "*If you have not done this, you will need to shut down your current cluster and start a new one with the `--packages-gnomad` argument.* \n",
    "\n",
    "See the tutorials [README](https://github.com/atgu/hgdp_tgp/tree/master/tutorials#readme) for more information on how to start a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee38a5",
   "metadata": {},
   "source": [
    "# Index\n",
    "1. [Setting Default Paths](#1.-Set-Default-Paths)\n",
    "2. [Variant Filtering and LD Pruning](#2.-Variant-Filtering-and-LD-Pruning)\n",
    "3. [Run PC Relate](#3.-Run-PC-Relate)\n",
    "4. [PCA](#4.-PCA)\n",
    "    1. [Function to Run PCA on Unrelated Individuals](#4a.-Function-to-Run-PCA-on-Unrelated-Individuals)\n",
    "    2. [Function to Project Related Individuals](#4b.-Function-to-Project-Related-Individuals)\n",
    "    3. [Global PCA](#4c.-Global-PCA)\n",
    "    4. [Subcontinental PCA](#4d.-Subcontinental-PCA)\n",
    "    5. [PCA Plots](#4e.-PCA-Plots)\n",
    "        1. [Global PCA Plots](#4e-1.-Global-PCA-Plots)\n",
    "        2. [Subcontinental PCA Plots](#4e-2.-Subcontinental-PCA-Plots)\n",
    "5. [Outlier Removal](#5.-Outlier-Removal)\n",
    "6. [Rerun PCA (without outliers)](#6.-Rerun-PCA-(without-outliers))\n",
    "    1. [Global PCA (without outliers)](#6a.-Global-PCA-(without-outliers))\n",
    "    2. [Subcontinental PCA (without outliers)](#6b.-Subcontinental-PCA-(without-outliers))\n",
    "    3. [PCA Plots (without outliers)](#6c.-PCA-Plots-(without-outliers))\n",
    "        1. [Global PCA Plots (without outliers)](#6c-1.-Global-PCA-Plots-(without-outliers))\n",
    "        2. [Subcontinental PCA Plots (without outliers)](#6c-2.-Subcontinental-PCA-Plots-(without-outliers))\n",
    "7. [Writing out Matrix Table](#7.-Write-Out-Matrix-Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb476d3",
   "metadata": {},
   "source": [
    "# General Overview \n",
    "The purpose of this notebook is to further filter the post-QC matrix table to prepare it for LD pruning, compute relatedness, and run Principal Component Analysis (PCA).\n",
    "\n",
    "**This script contains information on how to:**\n",
    "- Read in a matrix table and run Hail common variant statistics \n",
    "- Filter using allele frequency and call rate\n",
    "- Run LD pruning \n",
    "- Run relatedness and separate related and unrelated individuals\n",
    "- Calculate PC scores and project samples on to a PC space  \n",
    "- Run global and subcontinental PCA and plot them \n",
    "- Remove PCA outliers (filter using sample IDs)\n",
    "- Rerun global and subcontinental PCA\n",
    "- Write out a matrix table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf84dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "\n",
    "# Function from gnomAD for related sample projection \n",
    "from gnomad.sample_qc.ancestry import pc_project\n",
    "\n",
    "# For plotting in Hail\n",
    "from hail.ggplot import *\n",
    "import plotly\n",
    "\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff9552",
   "metadata": {},
   "source": [
    "# 1. Set Default Paths\n",
    "These default paths can be edited by users as needed. It is recommended to run these tutorials without writing out datasets.\n",
    "\n",
    "By default we have commented out all of the write steps of the tutorials, if you would like to write out your own datasets, uncomment those sections and replace the paths with your own. Don't forget to change the read-in paths as well. \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file \n",
    "post_qc_path = 'gs://hgdp-1kg/tutorial_datasets/metadata_and_qc/post_qc.mt'\n",
    "\n",
    "# Path for gnomAD's HGDP+1kGP metadata for plotting \n",
    "metadata_path = 'gs://hgdp-1kg/tutorial_datasets/metadata_and_qc/gnomad_meta_v1.tsv'\n",
    "\n",
    "# save the filtered and LD pruned mt as an intermediate file since LD pruning takes a while to rerun\n",
    "ld_pruned_path = 'gs://hgdp-1kg/tutorial_datasets/pca_preprocessing/ld_pruned.mt'\n",
    "\n",
    "# ht of related sample IDs for separating unrelated and related samples for PCA run \n",
    "related_sample_ids_path = 'gs://hgdp-1kg/tutorial_datasets/pca_preprocessing/related_sample_ids.ht'\n",
    "\n",
    "# path for pre-outlier PCA results - global & subcontinental PCA \n",
    "pc_scores_with_outliers_path = 'gs://hgdp-1kg/tutorial_datasets/pca/pc_scores_with_outliers/'\n",
    "\n",
    "# PCA outliers file \n",
    "outliers_path = 'gs://hgdp-1kg/tutorial_datasets/pca/pca_outliers.txt'\n",
    "\n",
    "# path for post-outlier PCA results - global & subcontinental PCA \n",
    "pc_scores_without_outliers_path = 'gs://hgdp-1kg/tutorial_datasets/pca/pc_scores_without_outliers/'\n",
    "\n",
    "# paths for unrelated and related datasets without outliers   \n",
    "unrelateds_mt_without_outliers_path = 'gs://hgdp-1kg/tutorial_datasets/pca_results/unrelateds_without_outliers.mt'\n",
    "relateds_mt_without_outliers_path = 'gs://hgdp-1kg/tutorial_datasets/pca_results/relateds_without_outliers.mt' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ef219",
   "metadata": {},
   "source": [
    "# 2. Variant Filtering and LD Pruning\n",
    "   \n",
    "At this point, we have <code>159,795,273 SNVs</code>. We want fewer variants (~100-300k) for PCA for computational efficiency, so we apply filters on: allele frequency (<code>AF</code>) and missingness (<code>call rate</code>), then run LD pruning.  \n",
    "\n",
    "Linkage disequilibrium (LD) is the correlation between nearby variants such that the alleles at neighboring polymorphisms (observed on the same chromosome) are associated within a population more often than if they were unlinked.    \n",
    "    \n",
    "For more information on LD pruning click <a href=\"https://www.nature.com/articles/nrg2361\"> here</a>.\n",
    "\n",
    "\n",
    "<br>\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "<ul>\n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/genetics.html#hail.methods.variant_qc\"> More on  <i> variant_qc() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/genetics.html#hail.methods.ld_prune\"> More on  <i> ld_prune() </i></a></li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the right input file \n",
    "mt = hl.read_matrix_table(post_qc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847954c",
   "metadata": {},
   "source": [
    "## 2a. Variant Filtering \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86284930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Hail's common variant statistics (QC metrics) \n",
    "var_qc_mt = hl.variant_qc(mt) \n",
    "\n",
    "\n",
    "# Filter to variants with AF between 0.05 & 0.95, and call rate greater than 0.999    \n",
    "filtered_mt = var_qc_mt.filter_rows(((var_qc_mt.variant_qc.AF[0] > 0.05) & (var_qc_mt.variant_qc.AF[1] > 0.05)) &\n",
    "                                 ((var_qc_mt.variant_qc.AF[0] < 0.95) & (var_qc_mt.variant_qc.AF[1] < 0.95)) &\n",
    "                                 (var_qc_mt.variant_qc.call_rate > 0.999))\n",
    "# Took 9min to print \n",
    "print('Num of variants after filtering = ' + str(filtered_mt.count()[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25badc",
   "metadata": {},
   "source": [
    "We started with <code>159,795,273</code> SNVs, then after filtering on allele frequency and call rate, we ended with <code>5,194,245</code> SNVs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9dfdb",
   "metadata": {},
   "source": [
    "## 2b. LD Pruning\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a161e4",
   "metadata": {},
   "source": [
    "We have too many variants for PCA that are also non-independent. We address this by pruning SNVs based on LD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe0173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated variants \n",
    "# Took 1hr & 15min to run \n",
    "pruned_mt = hl.ld_prune(filtered_mt.GT, r2=0.1, bp_window_size=500000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b52ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pruned_mt = filtered_mt.filter_rows(hl.is_defined(pruned_mt[filtered_mt.row_key])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d727145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took ~13min to print \n",
    "print('Num of variants after LD pruning = ' + str(filtered_pruned_mt.count()[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f0f7e",
   "metadata": {},
   "source": [
    "Since the number of variants after this step is now in the ~100-300k range, we proceed to the PCA analysis without any more adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3bb9ee",
   "metadata": {},
   "source": [
    "## 2c. Write out an intermediate file\n",
    "\n",
    "The LD pruning step takes a non-negligible amount of time to run, so to ensure that the downstream analyses steps don't take a very long time, we write out an intermediate file. This write out step should take around 16 minutes to run.\n",
    "\n",
    "\n",
    "If the user wishes to export their own intermediate file, they can do so by changing the intermediate file path. Once a file has been written out, the <code>overwrite</code> argument can be used to replace it with a new file or keep the original one.  \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing out an intermediate file to speed up subsequent analyses\n",
    "## Took ~16min to run\n",
    "#filtered_pruned_mt.write(ld_pruned_path, overwrite=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe38135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the intermediate file back in for subsequent analyses\n",
    "filtered_pruned_mt = hl.read_matrix_table(ld_pruned_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184eed4",
   "metadata": {},
   "source": [
    "# 3. Run PC Relate   \n",
    "\n",
    "When doing Principal Component Analysis (PCA), we need to separate the related and unrelated samples before computing the PC scores and plotting them. This is because if we compute PCA with the related samples in the data set, the population structure and clustering will be affected by the relatedness that exists among those samples. Thus, we first have to identify the related individuals by computing relatedness estimates (kinship statistic in this case) using a variant of the PC-Relate method in Hail. We used a minimum minor allele frequency (MAF) filter of 0.05, excluded sample pairs with kinship less than 0.05, and used 20 principal components (PC) to control for population structure. After getting the sample ID pairs for the related samples, we then separate the filtered and pruned mt into relateds and unrelateds.\n",
    "\n",
    "<br>\n",
    "We computed the kinship statistic using (metrics for <code>pc_relate</code>):\n",
    "    <ul>\n",
    "        <li>a minimum minor allele frequency filter of 0.05</li>\n",
    "        <li>excluding sample-pairs with kinship less than 0.05</li>\n",
    "        <li>20 principal components to control for population structure</li>\n",
    "    </ul>\n",
    "\n",
    "<br>    \n",
    "<details><summary>For more information on relatedness click <u><span style=\"color:blue\">here</span></u>.</summary>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4716688/\">Paper</a></li>\n",
    "        <li><a href=\"https://hail.is/docs/0.2/methods/relatedness.html#relatedness\">Hail documentation</a></li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "    <ul>\n",
    "        <li><a href=\"https://hail.is/docs/0.2/methods/relatedness.html#hail.methods.pc_relate\"> More on  <i> pc_relate() </i></a>\n",
    "        </li>\n",
    "        <li><a href=\"https://hail.is/docs/0.2/methods/misc.html#hail.methods.maximal_independent_set\"> More on  <i> maximal_independent_set() </i></a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute kinship statistic\n",
    "relatedness_ht = hl.pc_relate(\n",
    "    filtered_pruned_mt.GT, \n",
    "    min_individual_maf=0.05, \n",
    "    min_kinship=0.05, \n",
    "    statistics='kin', \n",
    "    k=20).key_by() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84a678",
   "metadata": {},
   "source": [
    "Since running <code>hl.maximal_independent_set</code> took ~2hr and 22min, we decided to write out the result and read it back in. This allowed subsequent runs to get executed faster and saves time while running through the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa8576",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify closely related individuals in pairs (list of sample IDs) \n",
    "#related_sample_ids = hl.maximal_independent_set(relatedness_ht.i, relatedness_ht.j, False) # 721 samples\n",
    "\n",
    "## Write out the sample IDs \n",
    "#related_sample_ids.write(related_sample_ids_path, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of related-sample IDs back in\n",
    "related_sample_ids = hl.read_table(related_sample_ids_path)\n",
    "\n",
    "# Subset the filtered and pruned mt to unrelated samples \n",
    "# Sample IDs that are NOT present in the list of related individuals  \n",
    "unrelateds_mt_preoutlier = filtered_pruned_mt.filter_cols(hl.is_defined(related_sample_ids[filtered_pruned_mt.col_key]), keep=False) \n",
    "\n",
    "# Do the same as above but this time subset to related samples \n",
    "# Sample IDs that are present in the list of related individuals    \n",
    "relateds_mt_preoutlier = filtered_pruned_mt.filter_cols(hl.is_defined(related_sample_ids[filtered_pruned_mt.col_key]), keep=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60a974",
   "metadata": {},
   "source": [
    "# 4. PCA\n",
    "\n",
    "PCA is run on the unrelated samples first. Then, the related samples are projected onto the PC space of the unrelated samples to get their PC scores. This way the population structure and clustering is not affected by the relatedness among samples.  \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6cf14",
   "metadata": {},
   "source": [
    "## 4a. Function to Run PCA on Unrelated Individuals\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f14e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca(mt: hl.MatrixTable):\n",
    "    \"\"\"\n",
    "    Runs PCA on a dataset\n",
    "    :param mt: dataset to run PCA on\n",
    "    :return: loadings and pc scores of unrelated samples \n",
    "    \"\"\"\n",
    "\n",
    "    pca_evals, pca_scores, pca_loadings = hl.hwe_normalized_pca(mt.GT, k=20, compute_loadings=True)\n",
    "    pca_mt = mt.annotate_rows(pca_af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2)\n",
    "    pca_loadings = pca_loadings.annotate(pca_af=pca_mt.rows()[pca_loadings.key].pca_af)\n",
    "    pca_scores = pca_scores.transmute(**{f'PC{i}': pca_scores.scores[i - 1] for i in range(1, 21)})\n",
    "    return pca_loadings, pca_scores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906e2ba",
   "metadata": {},
   "source": [
    "## 4b. Function to Project Related Individuals\n",
    "\n",
    "**If running the cell below results in an error, double check that you used the  `--packages gnomad` argument when starting your cluster.**  \n",
    "- See the tutorials [README](https://github.com/atgu/hgdp_tgp/tree/master/tutorials#readme) for more information on how to start a cluster.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25392b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_individuals(project_mt, pca_loadings, unrel_scores, out_path: str, reg_name:str, outlier_status:str):\n",
    "    \"\"\"\n",
    "    Project samples into predefined PCA space\n",
    "    :param project_mt: matrix table of related samples to project \n",
    "    :param pca_loadings: existing PCA space of unrelated samples \n",
    "    :param unrel_scores: unrelated samples' PC scores\n",
    "    :param out_path: path for where to save PCA projection outputs\n",
    "    :param reg_name: region name for saving output purposes\n",
    "    :param outlier_status: is the dataset with or without outliers? \n",
    "    \"\"\"\n",
    "    ht_projections = pc_project(project_mt, pca_loadings)  \n",
    "    ht_projections = ht_projections.transmute(**{f'PC{i}': ht_projections.scores[i - 1] for i in range(1, 21)}) \n",
    "    scores = unrel_scores.union(ht_projections) # combine the pc scores from both the unrelateds and relateds \n",
    "    scores.export(out_path + reg_name + '_scores_' + outlier_status + '.txt.bgz') # write output for plotting    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c77a62",
   "metadata": {},
   "source": [
    "## 4c. Global PCA\n",
    "\n",
    "We are doing this to see the population structure and clustering on a continental level and contextualize the data globally.    \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d656b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block took 23min to run \n",
    "\n",
    "# Dictionaries to hold unrelateds' PCA loadings and scores\n",
    "loadings_dict = {}\n",
    "unrel_scores_dict = {}\n",
    "\n",
    "# Run PCA on unrelated samples as whole\n",
    "loadings_dict['GLOBAL'], unrel_scores_dict['GLOBAL'] = run_pca(unrelateds_mt_preoutlier)  \n",
    "\n",
    "\n",
    "# Project related samples onto unrelated-samples' PC space \n",
    "project_individuals(relateds_mt_preoutlier, loadings_dict['GLOBAL'], unrel_scores_dict['GLOBAL'], pc_scores_with_outliers_path, 'GLOBAL', 'with_outliers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab006920",
   "metadata": {},
   "source": [
    "## 4d. Subcontinental PCA \n",
    "\n",
    "To see the population structure and clustering on a subcontinental level and contextualize data within continental regions. This also helped us identify outliers which were removed later on.     \n",
    "\n",
    "When running the following section, the notebook might freeze/throw an error after running PCA for 3-4 regions. Thus, we run it in groups of 3-4 regions at a time. If you want to run subcontinental PCA, we recommend doing that.\n",
    "\n",
    "<br>\n",
    "\n",
    "<details><summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "\n",
    "<ul>\n",
    "<li><a href=\"more info https://hail.is/docs/0.2/methods/genetics.html#hail.methods.hwe_normalized_pca\"> More on <i> hwe_normalized_pca() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.annotate_rows\"> More on <i> annotate_rows() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.annotate\"> More on <i> annotate() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.transmute\"> More on <i> transmute() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.export\"> More on <i> export() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/experimental/index.html#hail.experimental.pc_project\"> More on <i> pc_project() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.expr.Expression.html#hail.expr.Expression.collect\"> More on <i> collect() </i></a></li>\n",
    "</ul>\n",
    "    \n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf57b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run time breakdown for this cell is as follows:\n",
    "# 1hr & 42 min for EAS, AMR, CSA\n",
    "# 1hr & 23 min for EUR, AFR and OCE\n",
    "# 34 min for MID\n",
    "\n",
    "# dictionaries to hold unrelateds' PCA loadings and scores\n",
    "loadings_dict = {}\n",
    "unrel_scores_dict = {}\n",
    "regions = unrelateds_mt_preoutlier['hgdp_tgp_meta']['genetic_region'].collect() \n",
    "regions = list(dict.fromkeys(regions)) # convert into a list\n",
    "# There are 7 regions: EUR, AFR, AMR, EAS, CSA, OCE, and MID\n",
    "\n",
    "# for each region, run PCA on the unrelated samples \n",
    "for i in regions:  \n",
    "    if i is not None: # exclude a none value\n",
    "        # filter the unrelateds per region\n",
    "        subcont_unrelateds = unrelateds_mt_preoutlier.filter_cols(unrelateds_mt_preoutlier['hgdp_tgp_meta']['genetic_region'] == i) \n",
    "\n",
    "        # run PCA\n",
    "        loadings_dict[i], unrel_scores_dict[i] = run_pca(subcont_unrelateds)\n",
    "\n",
    "        # filter the related mt per region \n",
    "        subcont_relateds = relateds_mt_preoutlier.filter_cols(relateds_mt_preoutlier['hgdp_tgp_meta']['genetic_region'] == i)  \n",
    "\n",
    "        # project related samples onto unrelated-samples' PC space \n",
    "        project_individuals(subcont_relateds, loadings_dict[i], unrel_scores_dict[i], pc_scores_with_outliers_path, i, 'with_outliers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b296a",
   "metadata": {},
   "source": [
    "## 4e. PCA Plots\n",
    "\n",
    "The following PCA plots are prior to the removal of any outlier.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42433e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in gnomAD's HGDP+1kGP metadata for plotting \n",
    "metadata = hl.import_table(metadata_path, impute = True, key = 's')\n",
    "\n",
    "# Dictionary mapping colors to region names \n",
    "cont_colors = {'AMR':\"#E41A1C\",\n",
    "               'AFR':\"#984EA3\", \n",
    "               'OCE':\"#999999\",\n",
    "               'CSA':\"#FF7F00\",\n",
    "               'EAS':\"#4DAF4A\", \n",
    "               'EUR':\"#377EB8\", \n",
    "               'MID':\"#A65628\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68975858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize dictionary to save final data files to\n",
    "scores_with_outliers = {}\n",
    "\n",
    "# Loop through each region to create a curated dataset for each\n",
    "regions = ['GLOBAL', 'AFR', 'AMR', 'CSA', 'EAS', 'EUR', 'MID', 'OCE']\n",
    "\n",
    "for region in regions:\n",
    "    \n",
    "    # Import PC score tables\n",
    "    scores = hl.import_table(pc_scores_with_outliers_path + region + '_scores_with_outliers.txt.bgz', impute = True)\n",
    "    \n",
    "    # Add information from the metadata - genetic region and populations \n",
    "    scores = scores.annotate(\n",
    "        global_pop = metadata[scores.s]['hgdp_tgp_meta.Genetic.region'], \n",
    "        subpop = metadata[scores.s]['hgdp_tgp_meta.Population'],\n",
    "        global_color = metadata[scores.s]['hgdp_tgp_meta.Continent.colors'],\n",
    "        subpop_color = metadata[scores.s]['hgdp_tgp_meta.Pop.colors'],\n",
    "        subpop_shapes = metadata[scores.s]['hgdp_tgp_meta.Pop.shapes'],\n",
    "        proj_title = metadata[scores.s]['hgdp_tgp_meta.Project'])\n",
    "\n",
    "    # Save annotated table to dictionary \n",
    "    # For plotting, the score files can be accessed by indexing the dictionary using region names \n",
    "    scores_with_outliers[region] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c36ba3",
   "metadata": {},
   "source": [
    "### 4e-1. Global PCA Plots\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotated score table from dictionary \n",
    "global_with_outliers = scores_with_outliers['GLOBAL']\n",
    "\n",
    "# CHMI_CHMI3_WGS2 is a sample added by gnomAD for QC purposes and thus doesn't have metadata information. \n",
    "# To avoid a \"None\" error, we have to remove it before plotting. \n",
    "# From the dataset itself, it is removed together with PCA outliers in section 5 below. \n",
    "global_with_outliers = global_with_outliers.filter(global_with_outliers.s == 'CHMI_CHMI3_WGS2', keep = False)\n",
    "\n",
    "# Make plot\n",
    "p = ggplot(global_with_outliers, aes(x = global_with_outliers.PC1, y = global_with_outliers.PC2))+ \\\n",
    "    geom_point(aes(color = global_with_outliers.global_pop,\n",
    "                   shape = global_with_outliers.proj_title),\n",
    "                   size = 3, alpha = .5) +\\\n",
    "    xlab(\"PC1\") + \\\n",
    "    ylab(\"PC2\") + \\\n",
    "    ggtitle(\"Global PCA With Outliers\")+\\\n",
    "    labs(shape = 'Project', color = 'Population') +\\\n",
    "    scale_color_manual(values=cont_colors)\n",
    "\n",
    "# Show plot\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102982cb",
   "metadata": {},
   "source": [
    "### 4e-2. Subcontinental PCA Plots\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04fa6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to save each plot\n",
    "plots_with_outliers = {}\n",
    "\n",
    "for region in regions[1:]: # skip \"GLOBAL\" and only plot PCA for the 7 genetic regions \n",
    "    \n",
    "    # Filter for a specific region\n",
    "    subcont_with_outliers = scores_with_outliers[region]\n",
    "\n",
    "    # Only plotting PC1 vs PC2 but you can change the PC values or make a for loop to plot the rest of the PCs\n",
    "    p = ggplot(subcont_with_outliers, aes(x=subcont_with_outliers.PC1, y=subcont_with_outliers.PC2)) + \\\n",
    "        geom_point(aes(color = subcont_with_outliers.subpop, \n",
    "                       shape = subcont_with_outliers.proj_title),\n",
    "                       size = 3, alpha = .3) +\\\n",
    "        xlab(\"PC1\") + \\\n",
    "        ylab(\"PC2\") + \\\n",
    "        ggtitle(region + \" PCA With Outliers\")+\\\n",
    "        labs(shape = 'Project', color = 'Population')\n",
    "\n",
    "    # Add plot to dictionary with the region name as its key \n",
    "    plots_with_outliers[region] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ef4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show subcontinental PC1 vs PC2 plots one by one \n",
    "for region in regions[1:]:\n",
    "    plots_with_outliers[region].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c149462",
   "metadata": {},
   "source": [
    "# 5. Outlier Removal\n",
    "\n",
    "After [plotting the PCs](https://github.com/atgu/hgdp_tgp/blob/master/plot_pca.Rmd) using R, 24 outliers were identified. \n",
    "\n",
    "| sample ID | Genetic region | Population |\n",
    "| --- | --- | --- |\n",
    "| HG01880 | AFR | ACB |\n",
    "| HG01881 | AFR | ACB |\n",
    "| NA20274 | AFR | ASW |\n",
    "| NA20299 | AFR | ASW |\n",
    "| NA20314 | AFR | ASW |\n",
    "| HGDP00013 | CSA | Brahui |\n",
    "| HGDP00029 | CSA | Brahui |\n",
    "| HGDP00057 | CSA | Balochi |\n",
    "| HGDP00130 | CSA | Makrani |\n",
    "| HGDP00150 | CSA | Makrani |\n",
    "| HGDP00175 (This sample was discovered in the second PCA rerun) | CSA | Sindhi |\n",
    "| HGDP01298 | EAS | Uygur |\n",
    "| HGDP01300 | EAS | Uygur |\n",
    "| HGDP01303 | EAS | Uygur |\n",
    "| LP6005443-DNA_B02 | EAS | Uygur |\n",
    "| HG01628 | EUR | IBS | \n",
    "| HG01629 | EUR | IBS | \n",
    "| HG01630 | EUR | IBS | \n",
    "| HG01694 | EUR | IBS | \n",
    "| HG01696 | EUR | IBS |\n",
    "| HGDP00621 | MID | Bedouin |\n",
    "| HGDP01270 | MID | Mozabite |\n",
    "| HGDP01271 | MID | Mozabite |\n",
    "| CHMI_CHMI3_WGS2 | No metadata information available for this sample | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155586dc",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "    \n",
    "- <a href=\"more info https://hail.is/docs/0.2/utils/index.html#hail.utils.hadoop_open\"> More on  <i> hl.utils.hadoop_open() </i></a>\n",
    "    \n",
    "- <a href=\"more info https://hail.is/docs/0.2/functions/core.html#hail.expr.functions.literal\"> More on  <i> hl.literal() </i></a>\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the filtered and pruned dataset if not already done so \n",
    "filtered_pruned_mt = hl.read_matrix_table(ld_pruned_path)\n",
    "\n",
    "# Read in the PCA outliers file into a list\n",
    "with hl.utils.hadoop_open(outliers_path) as file: \n",
    "    outliers = [line.rstrip('\\n') for line in file]\n",
    "    \n",
    "# Capture and broadcast the list as an expression\n",
    "outliers_list = hl.literal(outliers)\n",
    "\n",
    "# Remove the 24 outliers from the pruned dataset \n",
    "mt_without_outliers = filtered_pruned_mt.filter_cols(~outliers_list.contains(filtered_pruned_mt['s']))\n",
    "\n",
    "# Validity check \n",
    "print('Before outlier removal: ' + str(filtered_pruned_mt.count()[1]))\n",
    "print('After outlier removal: ' + str(mt_without_outliers.count()[1])) \n",
    "num_outliers = filtered_pruned_mt.count()[1] - mt_without_outliers.count()[1]\n",
    "print('Total samples removed: ' + str(num_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00915971",
   "metadata": {},
   "source": [
    "# 6. Rerun PCA (without outliers)\n",
    "\n",
    "**Before running the sections below make sure you have run sections 4a (PCA) and 4b (Projection) above.**\n",
    "\n",
    "Here we are using the dataset without outliers and new paths for the outputs.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of related-sample IDs back in\n",
    "related_sample_ids = hl.read_table(related_sample_ids_path)\n",
    "\n",
    "# Divide the new dataset [one without the 24 outliers] to unrelated and related samples \n",
    "unrelateds_mt_postoutlier = mt_without_outliers.filter_cols(hl.is_defined(related_sample_ids[mt_without_outliers.col_key]), keep=False) \n",
    "relateds_mt_postoutlier = mt_without_outliers.filter_cols(hl.is_defined(related_sample_ids[mt_without_outliers.col_key]), keep=True)\n",
    "\n",
    "# Validity check \n",
    "print(unrelateds_mt_postoutlier.count()[1], relateds_mt_postoutlier.count()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb1330",
   "metadata": {},
   "source": [
    "## 6a. Global PCA (without outliers)\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell took 20 min to run\n",
    "\n",
    "# Dictionaries to hold unrelateds' PCA loadings and scores\n",
    "loadings_dict = {}\n",
    "unrel_scores_dict = {}\n",
    "\n",
    "# Run PCA on unrelated samples as a whole min \n",
    "loadings_dict['GLOBAL'], unrel_scores_dict['GLOBAL'] = run_pca(unrelateds_mt_postoutlier)  \n",
    "\n",
    "\n",
    "# Project related samples onto unrelated-samples' PC space \n",
    "project_individuals(relateds_mt_postoutlier, loadings_dict['GLOBAL'], unrel_scores_dict['GLOBAL'], pc_scores_without_outliers_path, 'GLOBAL', 'without_outliers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb195812",
   "metadata": {},
   "source": [
    "## 6b. Subcontinental PCA (without outliers)\n",
    "\n",
    "When running the following section, the notebook might freeze after printing the log for <code>EUR</code>, <code>AFR</code> and <code>AMR</code>. If this happens, do not restart it. Let it run and follow the progress with the outputs being generated at the path indicated.  \n",
    "\n",
    "When complete, check that there are 21 total output files (3 for each region) in your specified output path.\n",
    "\n",
    "Once you have confirmed you have the desired outputs, do the following:\n",
    "<ol type=\"1\">\n",
    "<li> Save close and halt the current notebook</li>\n",
    "<li> Open a new session</li>\n",
    "<li> Proceed to the next step (run <code>project_relateds</code> function first)</li>\n",
    "</ol>\n",
    "\n",
    "<br>\n",
    "<details><summary>For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "\n",
    "<ul>\n",
    "<li><a href=\"more info https://hail.is/docs/0.2/methods/genetics.html#hail.methods.hwe_normalized_pca\"> More on <i> hwe_normalized_pca() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.annotate_rows\"> More on <i> annotate_rows() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.annotate\"> More on <i> annotate() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.transmute\"> More on <i> transmute() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.Table.html#hail.Table.export\"> More on <i> export() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/experimental/index.html#hail.experimental.pc_project\"> More on <i> pc_project() </i></a></li>\n",
    "    \n",
    "<li><a href=\"more info https://hail.is/docs/0.2/hail.expr.Expression.html#hail.expr.Expression.collect\"> More on <i> collect() </i></a></li>\n",
    "    </ul>\n",
    "    \n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run time breakdown for this cell is as follows:\n",
    "# 1hr & 40min for EAS, AMR, CSA, OCE\n",
    "# 1hr & 42min for EUR, AFR, MID\n",
    "\n",
    "# Dictionaries to hold unrelateds' PCA loadings and scores  \n",
    "loadings_dict = {}\n",
    "unrel_scores_dict = {}\n",
    "regions = mt_without_outliers['hgdp_tgp_meta']['genetic_region'].collect() \n",
    "regions = list(dict.fromkeys(regions)) # convert into a list\n",
    "# There are 7 regions: EUR, AFR, AMR, EAS, CSA, OCE, and MID\n",
    "\n",
    "# For each region, run PCA on the unrelated samples \n",
    "for i in regions:  \n",
    "    if i is not None: # exclude a none value\n",
    "        # Filter the unrelateds per region\n",
    "        subcont_unrelateds = unrelateds_mt_postoutlier.filter_cols(unrelateds_mt_postoutlier['hgdp_tgp_meta']['genetic_region'] == i) \n",
    "\n",
    "        # Run PCA\n",
    "        loadings_dict[i], unrel_scores_dict[i] = run_pca(subcont_unrelateds)\n",
    "\n",
    "        # Filter the related mt per region \n",
    "        subcont_relateds = relateds_mt_postoutlier.filter_cols(relateds_mt_postoutlier['hgdp_tgp_meta']['genetic_region'] == i)  \n",
    "\n",
    "        # Project related samples onto unrelated-samples' PC space \n",
    "        project_individuals(subcont_relateds, loadings_dict[i], unrel_scores_dict[i], pc_scores_without_outliers_path, i, 'without_outliers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e976cbd",
   "metadata": {},
   "source": [
    "## 6c. PCA Plots (without outliers)\n",
    "\n",
    "The following PCA plots are after the removal of outliers.\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de83523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in gnomAD's HGDP+1kGP metadata for plotting \n",
    "metadata = hl.import_table(metadata_path, impute = True, key = 's')\n",
    "\n",
    "# Dictionary mapping colors to region names \n",
    "cont_colors = {'AMR':\"#E41A1C\",\n",
    "               'AFR':\"#984EA3\", \n",
    "               'OCE':\"#999999\",\n",
    "               'CSA':\"#FF7F00\",\n",
    "               'EAS':\"#4DAF4A\", \n",
    "               'EUR':\"#377EB8\", \n",
    "               'MID':\"#A65628\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1871efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize dictionary to save final data files to\n",
    "scores_without_outliers = {}\n",
    "\n",
    "# Loop through each region to create a curated dataset for each\n",
    "regions = ['GLOBAL', 'AFR', 'AMR', 'CSA', 'EAS', 'EUR', 'MID', 'OCE']\n",
    "\n",
    "for region in regions:\n",
    "    \n",
    "    # Import PC score tables\n",
    "    scores = hl.import_table(pc_scores_without_outliers_path + region + '_scores_without_outliers.txt.bgz', impute = True)\n",
    "    \n",
    "    # Add information from the metadata - genetic region and populations \n",
    "    scores = scores.annotate(\n",
    "        global_pop = metadata[scores.s]['hgdp_tgp_meta.Genetic.region'], \n",
    "        subpop = metadata[scores.s]['hgdp_tgp_meta.Population'],\n",
    "        global_color = metadata[scores.s]['hgdp_tgp_meta.Continent.colors'],\n",
    "        subpop_color = metadata[scores.s]['hgdp_tgp_meta.Pop.colors'],\n",
    "        subpop_shapes = metadata[scores.s]['hgdp_tgp_meta.Pop.shapes'],\n",
    "        proj_title = metadata[scores.s]['hgdp_tgp_meta.Project'])\n",
    "\n",
    "    # Save annotated table to dictionary \n",
    "    # For plotting, the score files can be accessed by indexing the dictionary using region names \n",
    "    scores_without_outliers[region] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548b5e3",
   "metadata": {},
   "source": [
    "### 6c-1. Global PCA Plots (without outliers)\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotated score table from dictionary \n",
    "global_without_outliers = scores_without_outliers['GLOBAL']\n",
    "\n",
    "# CHMI_CHMI3_WGS2 is a sample added by gnomAD for QC purposes and thus doesn't have metadata information. \n",
    "# To avoid a \"None\" error, we have to remove it before plotting. \n",
    "# From the dataset itself, it is removed together with PCA outliers in section 5 below. \n",
    "global_without_outliers = global_without_outliers.filter(global_without_outliers.s == 'CHMI_CHMI3_WGS2', keep = False)\n",
    "\n",
    "# Make plot\n",
    "p = ggplot(global_without_outliers, aes(x = global_without_outliers.PC1, y = global_without_outliers.PC2))+ \\\n",
    "    geom_point(aes(color = global_without_outliers.global_pop,\n",
    "                   shape = global_without_outliers.proj_title),\n",
    "                   size = 3, alpha = .5) +\\\n",
    "    xlab(\"PC1\") + \\\n",
    "    ylab(\"PC2\") + \\\n",
    "    ggtitle(\"Global PCA Without Outliers\")+\\\n",
    "    labs(shape = 'Project', color = 'Population') +\\\n",
    "    scale_color_manual(values=cont_colors)\n",
    "\n",
    "# Show plot\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f149e",
   "metadata": {},
   "source": [
    "### 6c-2. Subcontinental PCA Plots (without outliers)\n",
    "\n",
    "[Back to Index](#Index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6787b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to save each plot\n",
    "plots_without_outliers = {}\n",
    "\n",
    "for region in regions[1:]: # skip \"GLOBAL\" and only plot PCA for the 7 genetic regions \n",
    "    \n",
    "    # Filter for a specific region\n",
    "    subcont_without_outliers = scores_without_outliers[region]\n",
    "\n",
    "    # Only plotting PC1 vs PC2 but you can change the PC values or make a for loop to plot the rest of the PCs\n",
    "    p = ggplot(subcont_without_outliers, aes(x=subcont_without_outliers.PC1, y=subcont_without_outliers.PC2)) + \\\n",
    "        geom_point(aes(color = subcont_without_outliers.subpop, \n",
    "                       shape = subcont_without_outliers.proj_title),\n",
    "                       size = 3, alpha = .3) +\\\n",
    "        xlab(\"PC1\") + \\\n",
    "        ylab(\"PC2\") + \\\n",
    "        ggtitle(region + \" PCA Without Outliers\")+\\\n",
    "        labs(shape = 'Project', color = 'Population')\n",
    "\n",
    "    # Add plot to dictionary with the region name as its key \n",
    "    plots_without_outliers[region] = p\n",
    "    \n",
    "# Show subcontinental PC1 vs PC2 plots one by one \n",
    "for region in regions[1:]:\n",
    "    plots_without_outliers[region].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19918b2",
   "metadata": {},
   "source": [
    "# 7. Write Out Matrix Table \n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff5a39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separately write out mts of unrelated and related samples without outliers - 10min to run \n",
    "#unrelated mt\n",
    "unrelateds_mt_postoutlier.write(unrelateds_mt_without_outliers_path, overwrite=False)\n",
    "\n",
    "#related mt\n",
    "relateds_mt_postoutlier.write(relateds_mt_without_outliers_path, overwrite=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19734b3c",
   "metadata": {},
   "source": [
    "### NOTE: The PCA plots shown above can also be easily plotted in R. Click [here](https://github.com/atgu/hgdp_tgp/blob/master/plot_pca.Rmd) for more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5ef4f",
   "metadata": {},
   "source": [
    "[Back to Index](#Index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

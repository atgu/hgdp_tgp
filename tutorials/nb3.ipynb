{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be200f6f",
   "metadata": {},
   "source": [
    "# Summarizing Data Post QC\n",
    "\n",
    "Author: Zan Koenig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa7ade8",
   "metadata": {},
   "source": [
    "## Index\n",
    "1. [Setting Default Paths](#1.-Set-Default-Paths)\n",
    "2. [Organizing the dataset](#2.-Setting-up-data)\n",
    "3. [Annotating table with relatedness information](#3.-Annotating-table-with-relatedness-information)\n",
    "4. [Calculating statistics per population](#4.-Calculating-statistics-per-population)\n",
    "5. [Formatting table for exporting](#5.-Formatting-table-for-exporting)\n",
    "6. [Exporting final table](#6.-Exporting-final-table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ade984",
   "metadata": {},
   "source": [
    "# General Overview:\n",
    "\n",
    "The purpose of this script is to format and write out a tsv which will be used to create plots and summaries of the post-QC dataset in R.\n",
    "\n",
    "**This script contains information on how to:**\n",
    "- Select specific columns from a matrix table\n",
    "- Annotate filter flags onto a matrix table\n",
    "- Join the columns of two matrix tables\n",
    "- Join two tables\n",
    "- Group a matrix table by region, population \n",
    "- Use `hl.agg.stats` to calculate statics for a metric within a population\n",
    "- Count the number of samples where a filter flag equals True  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d235c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f3e21",
   "metadata": {},
   "source": [
    "# 1. Set Default Paths\n",
    "These default paths can be edited by users as needed. It is recommended to run these tutorials without writing out datasets. \n",
    "\n",
    "By default all of the write sections are shown as markdown cells. If you would like to write out your own datasets, you can copy the code and paste it into a new code cell. \n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file \n",
    "post_qc_path = 'gs://hgdp-1kg/tutorial_datasets/metadata_and_qc/post_qc.mt'\n",
    "\n",
    "# PCA outliers file \n",
    "outliers_path = 'gs://hgdp-1kg/tutorial_datasets/pca/pca_outliers.txt'\n",
    "\n",
    "# Paths to related and unrelated Matrix Tables (without outliers) - written out in Notebook 2: PCA and Ancestry Analyses\n",
    "unrelateds_path = 'gs://hgdp-1kg/tutorial_datasets/pca_results/unrelateds_without_outliers.mt'\n",
    "relateds_path = 'gs://hgdp-1kg/tutorial_datasets/pca_results/relateds_without_outliers.mt'\n",
    "\n",
    "# Path for final output table in tsv format\n",
    "final_table_path = 'gs://hgdp-1kg/tutorial_datasets/metadata_and_qc/post_qc_summary.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991893e",
   "metadata": {},
   "source": [
    "# 2. Setting up data\n",
    "\n",
    "Here we are walking through some steps to get the dataset ready for downstream analyses. We first create a table with only sample data, then select only the columns we need for the table we will write out. Next, we create a checkpoint of that table, to speed up downstream analysis steps.\n",
    " \n",
    "\n",
    "<details><summary>For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "<br>\n",
    "<li><a href=\"https://hail.is/docs/0.2/utils/index.html#hail.utils.hadoop_open\"> More on  <i> hadoop_open() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/genetics.html#hail.methods.sample_qc\"> More on  <i> sample_qc() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.cols\"> More on  <i> cols() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.Table.html#hail.Table.select\"> More on  <i> select() </i></a></li>    \n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/methods/impex.html#hail.methods.read_table\"> More on  <i> read_table() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.Table.html#hail.Table.count\"> More on  <i> count() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.Table.html#hail.Table.checkpoint\"> More on  <i> checkpoint() </i></a></li>\n",
    "     \n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in a version of the dataset which has gnomAD's variant and sample QC filters applied to it\n",
    "mt = hl.read_matrix_table(post_qc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing PCA outliers from the dataset\n",
    "# To read in the PCA outlier list, first need to read the file in as a list\n",
    "# Using hl.hadoop_open here which allows one to read in files into Hail from Google Cloud Storage\n",
    "with hl.utils.hadoop_open(outliers_path) as file:\n",
    "    outliers = [line.rstrip('\\n') for line in file]\n",
    "\n",
    "# Using hl.literal here to convert the list from a python object to a hail expression so that it can be used to filter out samples\n",
    "outliers_list = hl.literal(outliers)\n",
    "\n",
    "# Using the list of PCA outliers, using the ~ operator which is a negation operator and obtains the compliment\n",
    "# In this case the compliment is samples which are not contained in the pca outlier list\n",
    "mt_without_outliers = mt.filter_cols(~outliers_list.contains(mt['s']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0284e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_without_outliers.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ff382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing only the columns from the Matrix Table (outputs table of just columns)\n",
    "mt_col_table = mt_without_outliers.cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4635419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a col table with only the columns needed for table 1\n",
    "mt_col_table = mt_col_table.select(mt_col_table.hgdp_tgp_meta.genetic_region,\n",
    "                             mt_col_table.hgdp_tgp_meta.population,\n",
    "                             mt_col_table.sample_qc.n_snp, \n",
    "                             mt_col_table.bam_metrics.mean_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fee3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validity check - there should be 4096 samples \n",
    "mt_col_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing out col_table as a checkpoint to make the downstream steps run faster\n",
    "## This is done because running sample_qc is computationally expensive\n",
    "#col_table.checkpoint(checkpoint_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a table of only the columns with only postQC information\n",
    "col_table = hl.read_table(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since col_table is a table, count prints the number of rows which is equal to the number of samples\n",
    "# There should be 4096 samples\n",
    "mt_col_table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4e064",
   "metadata": {},
   "source": [
    "# 3. Annotating table with relatedness information\n",
    "\n",
    "Relatedness information is added to the dataset so that we can filter out related individuals. \n",
    "\n",
    "<details><summary>For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "    \n",
    "<br>\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.annotate_cols\"> More on  <i> annotate_cols() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/aggregators.html#hail.expr.aggregators.counter\"> More on  <i> counter() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.MatrixTable.html#hail.MatrixTable.union_cols\"> More on  <i> union_cols() </i></a></li>\n",
    "    \n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41743960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to get number of unrelateds annotated to the table\n",
    "\n",
    "# Reading in the unrelated and related Matrix Tables which were written out in notebook 2: PCA and Ancestry Analyses\n",
    "unrelateds = hl.read_matrix_table(unrelateds_path)\n",
    "relateds = hl.read_matrix_table(relateds_path)\n",
    "\n",
    "# Annotating both the unrelated and the related tables with a flag named unrelated \n",
    "# Set unrelated flag to True for those in the unrelated dataset, and False for those in the related dataset\n",
    "unrelateds = unrelateds.annotate_cols(unrelated = True)\n",
    "relateds = relateds.annotate_cols(unrelated = False)\n",
    "\n",
    "# Using hl.cols() to obtain two tables with only the columns from the original Matrix Tables\n",
    "unrelateds_cols = unrelateds.cols()\n",
    "relateds_cols = relateds.cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc9a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validity check \n",
    "print(unrelateds_cols.count(), relateds_cols.count()) # 3378 unrelated and 718 related samples = 4096 total samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c65d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotating the unrelated/related mts with counts per population\n",
    "unrelateds_count = unrelateds_cols.aggregate(hl.agg.counter(unrelateds_cols.hgdp_tgp_meta.population))\n",
    "relateds_count = relateds_cols.aggregate(hl.agg.counter(relateds_cols.hgdp_tgp_meta.population))\n",
    "\n",
    "# Validity check - print out the number of unrelated and related individuals per population \n",
    "print(f\"Number of unrelated individuals per population: \\\n",
    "{unrelateds_count}\\n\\nNumber of related individuals per population: {relateds_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the columns of the unrelated and related datasets\n",
    "mt_combined = unrelateds.union_cols(relateds)\n",
    "\n",
    "# Validity check - count the number of unrelateds (True values) in the Matrix Table to make sure it is as expected\n",
    "print(mt_combined.aggregate_cols(hl.agg.counter(mt_combined.unrelated))) # 3378 True and 718 False\n",
    "\n",
    "# Creating a table with only the columns from the Matrix Table containing related information\n",
    "# This is done since the final output will be a tsv and thus must be in table format\n",
    "# Being a table of columns allows it to be annotated onto the existing mt_col_table as shown below\n",
    "mt_combined_col_table = mt_combined.cols()\n",
    "\n",
    "# Annotating the relatedness information onto the column table\n",
    "mt_col_table = mt_col_table.annotate(unrelated = mt_combined_col_table[mt_col_table.s].unrelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea689f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_col_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960389a0",
   "metadata": {},
   "source": [
    "# 4. Calculating statistics per population\n",
    "In this section, we will be using `hl.agg.stats()` which calculates the following metrics for a given expression:\n",
    "- min\n",
    "- max\n",
    "- mean\n",
    "- standard deviation\n",
    "- number of non-missing records\n",
    "- sum\n",
    " \n",
    "Using `hl.group_by()` we calculate these statistics for each of the 78 populations in this dataset.\n",
    "We also count the number of related samples within each populations by using `hl.agg.count_where()` and counting the number of times the field denoting if samples are related or not is True.\n",
    "\n",
    "<br>\n",
    "<details><summary>For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "<br>\n",
    "<li><a href=\"https://hail.is/docs/0.2/aggregators.html#hail.expr.aggregators.stats\"> More on  <i> stats() </i></a></li>\n",
    "\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.Table.html#hail.Table.group_by\"> More on  <i> group_by() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/aggregators.html#hail.expr.aggregators.count_where\"> More on  <i> count_where() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.expr.TupleExpression.html#hail.expr.TupleExpression.show\"> More on <i>show()</i></a></li>\n",
    "     \n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating stats per population for each metric grouped by genetic region and population\n",
    "table = n_snp = mt_col_table.group_by(\n",
    "    mt_col_table.genetic_region, mt_col_table.population).aggregate(\n",
    "    n_snp_stats = hl.agg.stats(mt_col_table.n_snp),\n",
    "    cov_stats = hl.agg.stats(mt_col_table.mean_coverage),\n",
    "    n_unrelated = hl.agg.count_where(mt_col_table.unrelated == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965498ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that each of the table fields contain what we'd expect\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc6fef",
   "metadata": {},
   "source": [
    "# 5. Formatting table for exporting\n",
    "In this section, we format the table before exporting so it is in a usable format once written out. Specifically, we are flattening the table. This is done so that when the table is written out, the data is easier to work with. If the tables were written out without flattening them, the new annotated information would be in a nested structure which would make it difficult to work with outside hail. \n",
    "\n",
    "<br>\n",
    "<details><summary>For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "    \n",
    "<br>\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.Table.html#hail.Table.flatten\"> More on  <i> flatten() </i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.Table.html#hail.Table.key_by\"> More on <i>key_by()</i></a></li>\n",
    "    \n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.Table.html#hail.Table.describe\"> More on <i>describe()</i></a></li>\n",
    "    \n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6987e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening out the structs created from annotating the tables\n",
    "table = table.flatten()\n",
    "\n",
    "# Changing the keys of the table so that it is keyed by genetic region and population\n",
    "table = table.key_by(table.genetic_region, table.population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking format of the flattened table\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ad27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking on the format of the table after flattening to make sure it is what we'd expect\n",
    "table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One last validity check before writing out the dataset to make sure you still have the number of rows you expect\n",
    "# In this case, since the data is grouped by genetic region, population\n",
    "# The number of rows should be equal to the number of populations (78)\n",
    "table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c9199",
   "metadata": {},
   "source": [
    "# 6. Exporting final table\n",
    "<br>\n",
    "<details><summary>For more information on Hail methods and expressions click <u><span style=\"color:blue\">here</span></u>.</summary> \n",
    "<br>\n",
    "<li><a href=\"https://hail.is/docs/0.2/hail.Table.html#hail.Table.export\"> More on  <i> export() </i></a></li>\n",
    "\n",
    "</details>\n",
    "\n",
    "[Back to Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83331374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing out the final table in tsv format \n",
    "table.export(final_table_path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe1197",
   "metadata": {},
   "source": [
    "[Back to Index](#Index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

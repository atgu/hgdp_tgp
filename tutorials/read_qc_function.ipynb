{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb1fffa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import hail as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699c594e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 3.1.2\n",
      "SparkUI available at http://znk-m.c.diverse-pop-seq-ref.internal:44669\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.95-513139587f57\n",
      "LOGGING: writing to /home/hail/hail-20220614-1752-0.2.95-513139587f57.log\n"
     ]
    }
   ],
   "source": [
    "# trying to fix requester pays bucket issue\n",
    "# setting requester pays bucket to use throughout tutorial\n",
    "GCP_PROJECT_NAME = \"diverse-pop-seq-ref\"\n",
    "hl.init(spark_conf={\n",
    "    'spark.hadoop.fs.gs.requester.pays.mode': 'CUSTOM',\n",
    "    'spark.hadoop.fs.gs.requester.pays.buckets': 'hgdp_tgp,gcp-public-data--gnomad',\n",
    "    'spark.hadoop.fs.gs.requester.pays.project.id': 'diverse-pop-seq-ref'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a1d09",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Reading Function\n",
    "This function serves the purpose of reading in the dataset of different stages throughout the tutorial and given certain flags, will allow the user to specify which filters they would like run on the dataset. This function helps to reduce the amount of times data needs to be written out, overall decreasing the computational and monetary cost of running the tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a156e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_qc(\n",
    "        default: bool = False,\n",
    "        sample_qc: bool = False,\n",
    "        variant_qc: bool = False,\n",
    "        duplicate: bool = False,\n",
    "        outlier_removal: bool = False,\n",
    "        ld_pruning: bool = False,\n",
    "        rel_unrel: str = 'default') -> hl.MatrixTable:\n",
    "    \"\"\"\n",
    "    Wrapper function to get HGDP+1kGP data as Matrix Table at different stages of QC/filtering.\n",
    "    By default, returns pre QC MatrixTable with qc filters annotated but not filtered.\n",
    "\n",
    "    :param bool default: if True will preQC version of the dataset\n",
    "    :param bool sample_qc: if True will return a post sample QC matrix table\n",
    "    :param bool variant_qc: if True will return a post variant QC matrix table\n",
    "    :param bool duplicate: if True will return a matrix table with duplicate samples removed\n",
    "    :param bool outlier_removal: if True will return a matrix table with PCA outliers and duplicate samples removed\n",
    "    :param bool ld_pruning: if True will return a matrix table that has gone through:\n",
    "        - sample QC\n",
    "        - variant QC\n",
    "        - PCA outlier removal\n",
    "        - duplicate removal\n",
    "        - LD pruning\n",
    "        - additional variant filtering\n",
    "    :param bool rel_unrel: default will return same mt as ld pruned above\n",
    "        if 'related' will return a matrix table with only related samples.\n",
    "        if 'unrelated' will return my with only unrelated samples\n",
    "    \"\"\"\n",
    "    # Reading in all the tables and matrix tables needed to generate the pre_qc matrix table\n",
    "    sample_meta = hl.import_table('gs://hgdp-1kg/hgdp_tgp/qc_and_figure_generation/gnomad_meta_v1.tsv')\n",
    "    sample_qc_meta = hl.read_table('gs://hgdp_tgp/output/gnomad_v3.1_sample_qc_metadata_hgdp_tgp_subset.ht')\n",
    "    var_meta = hl.read_table(\n",
    "        'gs://gcp-public-data--gnomad/release/3.1.1/ht/genomes/gnomad.genomes.v3.1.1.sites.ht', n_partitions=5000)\n",
    "    dense_mt = hl.read_matrix_table('gs://hgdp_tgp/output/tgp_hgdp.mt')\n",
    "\n",
    "    # Takes a list of dicts and converts it to a struct format (works with nested structs too)\n",
    "    def dict_to_struct(d):\n",
    "        fields = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                v = dict_to_struct(v)\n",
    "            fields[k] = v\n",
    "        return hl.struct(**fields)\n",
    "\n",
    "    # un-flattening a hail table with nested structure\n",
    "    # dict to hold struct names as well as nested field names\n",
    "    d = {}\n",
    "\n",
    "    # Getting the row field names\n",
    "    row = sample_meta.row_value\n",
    "\n",
    "    # returns a dict with the struct names as keys and their inner field names as values\n",
    "    for name in row:\n",
    "        def recur(dict_ref, split_name):\n",
    "            if len(split_name) == 1:\n",
    "                dict_ref[split_name[0]] = row[name]\n",
    "                return\n",
    "            existing = dict_ref.get(split_name[0])\n",
    "            if existing is not None:\n",
    "                assert isinstance(existing, dict), existing\n",
    "                recur(existing, split_name[1:])\n",
    "            else:\n",
    "                existing = {}\n",
    "                dict_ref[split_name[0]] = existing\n",
    "                recur(existing, split_name[1:])\n",
    "        recur(d, name.split('.'))\n",
    "\n",
    "    # using the dict created from flattened struct, creating new structs now un-flattened\n",
    "    sample_meta = sample_meta.select(**dict_to_struct(d))\n",
    "    sample_meta = sample_meta.key_by('s')\n",
    "\n",
    "    # grabbing the columns needed from Alicia's metadata\n",
    "    new_meta = sample_meta.select(sample_meta.hgdp_tgp_meta, sample_meta.bergstrom)\n",
    "\n",
    "    # creating a table with gnomAD sample metadata and HGDP metadata\n",
    "    ht = sample_qc_meta.annotate(**new_meta[sample_qc_meta.s])\n",
    "\n",
    "    # stripping 'v3.1::' from the names to match with the densified MT\n",
    "    ht = ht.key_by(s=ht.s.replace(\"v3.1::\", \"\"))\n",
    "\n",
    "    # Using hl.annotate_cols() method to annotate the gnomAD variant QC metadata onto the matrix table\n",
    "    mt = dense_mt.annotate_cols(**ht[dense_mt.s])\n",
    "\n",
    "    # annotating preQC dataset with variant metadata\n",
    "    mt = mt.annotate_rows(**var_meta[mt.locus, mt.alleles])\n",
    "\n",
    "    print(f\"sample_qc: {sample_qc}\\nvariant_qc: {variant_qc}\\nduplicate: {duplicate}\\noutlier_removal: { outlier_removal}\\nld_pruning: {ld_pruning}\\nrel_unrel: {rel_unrel}\")\n",
    "\n",
    "    if default:\n",
    "        print(\"Returning default preQC matrix table\")\n",
    "        # returns preQC dataset\n",
    "        return mt\n",
    "\n",
    "    if sample_qc:\n",
    "        print(\"Running sample QC\")\n",
    "        # run data through sample QC\n",
    "        # filtering samples to those who should pass gnomADs sample QC\n",
    "        # this filters to only samples that passed gnomad sample QC hard filters\n",
    "        mt = mt.filter_cols(~mt.sample_filters.hard_filtered)\n",
    "\n",
    "        # annotating partially filtered dataset with variant metadata\n",
    "        mt = mt.annotate_rows(**var_meta[mt.locus, mt.alleles])\n",
    "\n",
    "    if variant_qc:\n",
    "        print(\"Running variant QC\")\n",
    "        # run data through variant QC\n",
    "        # Subsetting the variants in the dataset to only PASS variants (those which passed gnomAD's variant QC)\n",
    "        # PASS variants are variants which have an entry in the filters field.\n",
    "        # This field contains an array which contains a bool if any variant qc filter was failed\n",
    "        # This is the last step in the QC process\n",
    "        mt = mt.filter_rows(hl.len(mt.filters) != 0, keep=False)\n",
    "\n",
    "    if duplicate:\n",
    "        print(\"Removing duplicate sample\")\n",
    "        # Removing any duplicates in the dataset using hl.distinct_by_col() which removes\n",
    "        # columns with a duplicate column key. It keeps one column for each unique key.\n",
    "        mt = mt.distinct_by_col()\n",
    "\n",
    "    if outlier_removal:\n",
    "        print(\"Removing PCA outliers\")\n",
    "        # remove PCA outliers and duplicates\n",
    "        # reading in the PCA outlier list\n",
    "        # To read in the PCA outlier list, first need to read the file in as a list\n",
    "        # using hl.hadoop_open here which allows one to read in files into hail from Google cloud storage\n",
    "        pca_outlier_path = 'gs://hgdp-1kg/hgdp_tgp/pca_outliers_v2.txt'\n",
    "        with hl.utils.hadoop_open(pca_outlier_path) as file:\n",
    "            outliers = [line.rstrip('\\n') for line in file]\n",
    "\n",
    "        # Using hl.literal here to convert the list from a python object to a hail expression so that it can be used\n",
    "        # to filter out samples\n",
    "        outliers_list = hl.literal(outliers)\n",
    "\n",
    "        # Using the list of PCA outliers, using the ~ operator which is a negation operator and obtains the compliment\n",
    "        # In this case the compliment is samples which are not contained in the pca outlier list\n",
    "        mt = mt.filter_cols(~outliers_list.contains(mt['s']))\n",
    "\n",
    "    if ld_pruning:\n",
    "        print(\"Returning ld pruned post QC matrix table pre PCA outlier removal \")\n",
    "        # read in dataset which has additional variant filtering and ld pruning run\n",
    "        # data has gone through:\n",
    "        #   - sample QC\n",
    "        #   - variant QC\n",
    "        #   - duplicate removal\n",
    "        mt = hl.read_matrix_table('gs://hgdp-1kg/hgdp_tgp/intermediate_files/filtered_n_pruned_output_updated.mt')\n",
    "\n",
    "    if rel_unrel == \"all\":\n",
    "        print(\"Returning post QC matrix table pre PCA outlier removal with related & unrelated individuals\")\n",
    "        # need to check what steps this dataset has gone through, this is something to discuss with Mary\n",
    "        # data has gone through:\n",
    "        #   - sample QC\n",
    "        #   - variant QC\n",
    "        #   - duplicate removal\n",
    "        #   - LD pruning\n",
    "        mt = hl.read_matrix_table('gs://hgdp-1kg/hgdp_tgp/intermediate_files/filtered_n_pruned_output_updated.mt')\n",
    "\n",
    "    elif rel_unrel == 'related':\n",
    "        print(\"Returning post QC matrix table pre PCA outlier removal with only related individuals\")\n",
    "        # data has gone through:\n",
    "        #   - sample QC\n",
    "        #   - variant QC\n",
    "        #   - duplicate removal\n",
    "        #   - LD pruning\n",
    "        #   - pc_relate - filter to only related individuals\n",
    "        mt = hl.read_matrix_table('gs://hgdp-1kg/hgdp_tgp/rel_updated.mt')\n",
    "\n",
    "\n",
    "    elif rel_unrel == 'unrelated':\n",
    "        print(\"Returning post QC matrix table with only unrelated individuals\")\n",
    "        # data has gone through:\n",
    "        #   - sample QC\n",
    "        #   - variant QC\n",
    "        #   - duplicate removal\n",
    "        #   - LD pruning\n",
    "        #   - pc_relate - filter to only unrelated individuals\n",
    "        mt = hl.read_matrix_table('gs://hgdp-1kg/hgdp_tgp/unrel_updated.mt')\n",
    "\n",
    "\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fdd2b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 17:52:34 Hail: INFO: Loading <StructExpression of type struct{s: str, `project_meta.sample_id`: str, `project_meta.research_project_key`: str, `project_meta.seq_project`: str, `project_meta.ccdg_alternate_sample_id`: str, `project_meta.ccdg_gender`: str, `project_meta.ccdg_center`: str, `project_meta.ccdg_study`: str, `project_meta.cram_path`: str, `project_meta.project_id`: str, `project_meta.v2_age`: str, `project_meta.v2_sex`: str, `project_meta.v2_hard_filters`: str, `project_meta.v2_perm_filters`: str, `project_meta.v2_pop_platform_filters`: str, `project_meta.v2_related`: str, `project_meta.v2_data_type`: str, `project_meta.v2_product`: str, `project_meta.v2_product_simplified`: str, `project_meta.v2_qc_platform`: str, `project_meta.v2_project_id`: str, `project_meta.v2_project_description`: str, `project_meta.v2_internal`: str, `project_meta.v2_investigator`: str, `project_meta.v2_known_pop`: str, `project_meta.v2_known_subpop`: str, `project_meta.v2_pop`: str, `project_meta.v2_subpop`: str, `project_meta.v2_neuro`: str, `project_meta.v2_control`: str, `project_meta.v2_topmed`: str, `project_meta.v2_high_quality`: str, `project_meta.v2_release`: str, `project_meta.v2_pcr_free`: str, `project_meta.v2_project_name`: str, `project_meta.v2_release_2_0_2`: str, `project_meta.project_ancestry`: str, `project_meta.project_pop`: str, `project_meta.project_subpop`: str, `project_meta.pdo_owner`: str, `project_meta.category`: str, `project_meta.contact_pi`: str, `project_meta.sample_pi`: str, `project_meta.pm`: str, `project_meta.research_project`: str, `project_meta.pdo`: str, `project_meta.title`: str, `project_meta.product`: str, `project_meta.probably_releasable`: str, `project_meta.releasable`: str, `project_meta.broad_external`: str, `project_meta.sex`: str, `project_meta.subpop_description`: str, `project_meta.exclude`: str, `project_meta.exclude_reason`: str, `project_meta.case_control`: str, `project_meta.age`: str, `project_meta.age_bin`: str, `project_meta.tcga_tumor`: str, `project_meta.age_alt`: str, `project_meta.v2_s_match`: str, `project_meta.topmed`: str, `project_meta.neuro_cohort`: str, `project_meta.neuro_case`: str, `subsets.non_topmed`: str, `subsets.controls_and_biobanks`: str, `subsets.non_neuro`: str, `subsets.non_v2`: str, `subsets.non_cancer`: str, `subsets.tgp`: str, `subsets.hgdp`: str, `bam_metrics.pct_bases_20x`: str, `bam_metrics.pct_chimeras`: str, `bam_metrics.freemix`: str, `bam_metrics.mean_coverage`: str, `bam_metrics.median_coverage`: str, `bam_metrics.mean_insert_size`: str, `bam_metrics.median_insert_size`: str, `bam_metrics.pct_bases_10x`: str, `sex_imputation.is_female`: str, `sex_imputation.chr20_mean_dp`: str, `sex_imputation.chrX_mean_dp`: str, `sex_imputation.chrY_mean_dp`: str, `sex_imputation.chrX_ploidy`: str, `sex_imputation.chrY_ploidy`: str, `sex_imputation.X_karyotype`: str, `sex_imputation.Y_karyotype`: str, `sex_imputation.sex_karyotype`: str, `sex_imputation.impute_sex_stats.f_stat`: str, `sex_imputation.impute_sex_stats.n_called`: str, `sex_imputation.impute_sex_stats.expected_homs`: str, `sex_imputation.impute_sex_stats.observed_homs`: str, `sample_qc.n_hom_ref`: str, `sample_qc.n_het`: str, `sample_qc.n_hom_var`: str, `sample_qc.n_non_ref`: str, `sample_qc.n_singleton`: str, `sample_qc.n_snp`: str, `sample_qc.n_insertion`: str, `sample_qc.n_deletion`: str, `sample_qc.n_transition`: str, `sample_qc.n_transversion`: str, `sample_qc.n_star`: str, `sample_qc.r_ti_tv`: str, `sample_qc.r_het_hom_var`: str, `sample_qc.r_insertion_deletion`: str, `sample_qc.n_snp_residual`: str, `sample_qc.n_singleton_residual`: str, `sample_qc.r_ti_tv_residual`: str, `sample_qc.r_insertion_deletion_residual`: str, `sample_qc.n_insertion_residual`: str, `sample_qc.n_deletion_residual`: str, `sample_qc.r_het_hom_var_residual`: str, `sample_qc.n_transition_residual`: str, `sample_qc.n_transversion_residual`: str, `population_inference.training_pop`: str, `population_inference.pca_scores`: str, `population_inference.pop`: str, `population_inference.prob_afr`: str, `population_inference.prob_ami`: str, `population_inference.prob_amr`: str, `population_inference.prob_asj`: str, `population_inference.prob_eas`: str, `population_inference.prob_fin`: str, `population_inference.prob_mid`: str, `population_inference.prob_nfe`: str, `population_inference.prob_oth`: str, `population_inference.prob_sas`: str, `population_inference.training_pop_all`: str, `sample_filters.sex_aneuploidy`: str, `sample_filters.insert_size`: str, `sample_filters.chimera`: str, `sample_filters.contamination`: str, `sample_filters.bad_qc_metrics`: str, `sample_filters.low_coverage`: str, `sample_filters.ambiguous_sex`: str, `sample_filters.failed_fingerprinting`: str, `sample_filters.TCGA_tumor_sample`: str, `sample_filters.hard_filters`: str, `sample_filters.hard_filtered`: str, `sample_filters.release_related`: str, `sample_filters.release_duplicate`: str, `sample_filters.release_parent_child`: str, `sample_filters.release_sibling`: str, `sample_filters.all_samples_related`: str, `sample_filters.all_samples_duplicate`: str, `sample_filters.all_samples_parent_child`: str, `sample_filters.all_samples_sibling`: str, `sample_filters.fail_n_snp_residual`: str, `sample_filters.fail_n_singleton_residual`: str, `sample_filters.fail_r_ti_tv_residual`: str, `sample_filters.fail_r_insertion_deletion_residual`: str, `sample_filters.fail_n_insertion_residual`: str, `sample_filters.fail_n_deletion_residual`: str, `sample_filters.fail_r_het_hom_var_residual`: str, `sample_filters.fail_n_transition_residual`: str, `sample_filters.fail_n_transversion_residual`: str, `sample_filters.qc_metrics_filters`: str, `relatedness_inference.relationships`: str, high_quality: str, release: str, `bergstrom.hgdp`: str, `bergstrom.lp`: str, `bergstrom.source`: str, `bergstrom.library_type`: str, `bergstrom.region`: str, `bergstrom.sex`: str, `bergstrom.coverage`: str, `bergstrom.freemix`: str, `bergstrom.capmq`: str, `bergstrom.insert_size_average`: str, `bergstrom.array_non_reference_discordance`: str, `bergstrom.sample`: str, `hgdp_tgp_meta.Project`: str, `hgdp_tgp_meta.Study.region`: str, `hgdp_tgp_meta.Population`: str, `hgdp_tgp_meta.Genetic.region`: str, `hgdp_tgp_meta.Latitude`: str, `hgdp_tgp_meta.Longitude`: str, `hgdp_tgp_meta.Continent.colors`: str, `hgdp_tgp_meta.n`: str, `hgdp_tgp_meta.rownum`: str, `hgdp_tgp_meta.Pop.colors`: str, `hgdp_tgp_meta.Pop.shapes`: str}> fields. Counts by type:\n",
      "  str: 184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_qc: False\n",
      "variant_qc: False\n",
      "duplicate: False\n",
      "outlier_removal: False\n",
      "ld_pruning: False\n",
      "rel_unrel: default\n",
      "Returning default preQC matrix table\n"
     ]
    }
   ],
   "source": [
    "pre_qc = read_qc(default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c4f7d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211358784, 4151)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_qc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "403a2cf8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 18:48:49 Hail: INFO: Loading 184 fields. Counts by type:\n",
      "  str: 184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_qc: True\n",
      "variant_qc: False\n",
      "duplicate: False\n",
      "outlier_removal: False\n",
      "Running sample QC\n"
     ]
    }
   ],
   "source": [
    "post_sample = read_qc(sample_qc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83126c96",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211358784, 4120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This takes a negligible amount of time to run\n",
    "post_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dfe074c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:07:15 Hail: INFO: Loading <StructExpression of type struct{s: str, `project_meta.sample_id`: str, `project_meta.research_project_key`: str, `project_meta.seq_project`: str, `project_meta.ccdg_alternate_sample_id`: str, `project_meta.ccdg_gender`: str, `project_meta.ccdg_center`: str, `project_meta.ccdg_study`: str, `project_meta.cram_path`: str, `project_meta.project_id`: str, `project_meta.v2_age`: str, `project_meta.v2_sex`: str, `project_meta.v2_hard_filters`: str, `project_meta.v2_perm_filters`: str, `project_meta.v2_pop_platform_filters`: str, `project_meta.v2_related`: str, `project_meta.v2_data_type`: str, `project_meta.v2_product`: str, `project_meta.v2_product_simplified`: str, `project_meta.v2_qc_platform`: str, `project_meta.v2_project_id`: str, `project_meta.v2_project_description`: str, `project_meta.v2_internal`: str, `project_meta.v2_investigator`: str, `project_meta.v2_known_pop`: str, `project_meta.v2_known_subpop`: str, `project_meta.v2_pop`: str, `project_meta.v2_subpop`: str, `project_meta.v2_neuro`: str, `project_meta.v2_control`: str, `project_meta.v2_topmed`: str, `project_meta.v2_high_quality`: str, `project_meta.v2_release`: str, `project_meta.v2_pcr_free`: str, `project_meta.v2_project_name`: str, `project_meta.v2_release_2_0_2`: str, `project_meta.project_ancestry`: str, `project_meta.project_pop`: str, `project_meta.project_subpop`: str, `project_meta.pdo_owner`: str, `project_meta.category`: str, `project_meta.contact_pi`: str, `project_meta.sample_pi`: str, `project_meta.pm`: str, `project_meta.research_project`: str, `project_meta.pdo`: str, `project_meta.title`: str, `project_meta.product`: str, `project_meta.probably_releasable`: str, `project_meta.releasable`: str, `project_meta.broad_external`: str, `project_meta.sex`: str, `project_meta.subpop_description`: str, `project_meta.exclude`: str, `project_meta.exclude_reason`: str, `project_meta.case_control`: str, `project_meta.age`: str, `project_meta.age_bin`: str, `project_meta.tcga_tumor`: str, `project_meta.age_alt`: str, `project_meta.v2_s_match`: str, `project_meta.topmed`: str, `project_meta.neuro_cohort`: str, `project_meta.neuro_case`: str, `subsets.non_topmed`: str, `subsets.controls_and_biobanks`: str, `subsets.non_neuro`: str, `subsets.non_v2`: str, `subsets.non_cancer`: str, `subsets.tgp`: str, `subsets.hgdp`: str, `bam_metrics.pct_bases_20x`: str, `bam_metrics.pct_chimeras`: str, `bam_metrics.freemix`: str, `bam_metrics.mean_coverage`: str, `bam_metrics.median_coverage`: str, `bam_metrics.mean_insert_size`: str, `bam_metrics.median_insert_size`: str, `bam_metrics.pct_bases_10x`: str, `sex_imputation.is_female`: str, `sex_imputation.chr20_mean_dp`: str, `sex_imputation.chrX_mean_dp`: str, `sex_imputation.chrY_mean_dp`: str, `sex_imputation.chrX_ploidy`: str, `sex_imputation.chrY_ploidy`: str, `sex_imputation.X_karyotype`: str, `sex_imputation.Y_karyotype`: str, `sex_imputation.sex_karyotype`: str, `sex_imputation.impute_sex_stats.f_stat`: str, `sex_imputation.impute_sex_stats.n_called`: str, `sex_imputation.impute_sex_stats.expected_homs`: str, `sex_imputation.impute_sex_stats.observed_homs`: str, `sample_qc.n_hom_ref`: str, `sample_qc.n_het`: str, `sample_qc.n_hom_var`: str, `sample_qc.n_non_ref`: str, `sample_qc.n_singleton`: str, `sample_qc.n_snp`: str, `sample_qc.n_insertion`: str, `sample_qc.n_deletion`: str, `sample_qc.n_transition`: str, `sample_qc.n_transversion`: str, `sample_qc.n_star`: str, `sample_qc.r_ti_tv`: str, `sample_qc.r_het_hom_var`: str, `sample_qc.r_insertion_deletion`: str, `sample_qc.n_snp_residual`: str, `sample_qc.n_singleton_residual`: str, `sample_qc.r_ti_tv_residual`: str, `sample_qc.r_insertion_deletion_residual`: str, `sample_qc.n_insertion_residual`: str, `sample_qc.n_deletion_residual`: str, `sample_qc.r_het_hom_var_residual`: str, `sample_qc.n_transition_residual`: str, `sample_qc.n_transversion_residual`: str, `population_inference.training_pop`: str, `population_inference.pca_scores`: str, `population_inference.pop`: str, `population_inference.prob_afr`: str, `population_inference.prob_ami`: str, `population_inference.prob_amr`: str, `population_inference.prob_asj`: str, `population_inference.prob_eas`: str, `population_inference.prob_fin`: str, `population_inference.prob_mid`: str, `population_inference.prob_nfe`: str, `population_inference.prob_oth`: str, `population_inference.prob_sas`: str, `population_inference.training_pop_all`: str, `sample_filters.sex_aneuploidy`: str, `sample_filters.insert_size`: str, `sample_filters.chimera`: str, `sample_filters.contamination`: str, `sample_filters.bad_qc_metrics`: str, `sample_filters.low_coverage`: str, `sample_filters.ambiguous_sex`: str, `sample_filters.failed_fingerprinting`: str, `sample_filters.TCGA_tumor_sample`: str, `sample_filters.hard_filters`: str, `sample_filters.hard_filtered`: str, `sample_filters.release_related`: str, `sample_filters.release_duplicate`: str, `sample_filters.release_parent_child`: str, `sample_filters.release_sibling`: str, `sample_filters.all_samples_related`: str, `sample_filters.all_samples_duplicate`: str, `sample_filters.all_samples_parent_child`: str, `sample_filters.all_samples_sibling`: str, `sample_filters.fail_n_snp_residual`: str, `sample_filters.fail_n_singleton_residual`: str, `sample_filters.fail_r_ti_tv_residual`: str, `sample_filters.fail_r_insertion_deletion_residual`: str, `sample_filters.fail_n_insertion_residual`: str, `sample_filters.fail_n_deletion_residual`: str, `sample_filters.fail_r_het_hom_var_residual`: str, `sample_filters.fail_n_transition_residual`: str, `sample_filters.fail_n_transversion_residual`: str, `sample_filters.qc_metrics_filters`: str, `relatedness_inference.relationships`: str, high_quality: str, release: str, `bergstrom.hgdp`: str, `bergstrom.lp`: str, `bergstrom.source`: str, `bergstrom.library_type`: str, `bergstrom.region`: str, `bergstrom.sex`: str, `bergstrom.coverage`: str, `bergstrom.freemix`: str, `bergstrom.capmq`: str, `bergstrom.insert_size_average`: str, `bergstrom.array_non_reference_discordance`: str, `bergstrom.sample`: str, `hgdp_tgp_meta.Project`: str, `hgdp_tgp_meta.Study.region`: str, `hgdp_tgp_meta.Population`: str, `hgdp_tgp_meta.Genetic.region`: str, `hgdp_tgp_meta.Latitude`: str, `hgdp_tgp_meta.Longitude`: str, `hgdp_tgp_meta.Continent.colors`: str, `hgdp_tgp_meta.n`: str, `hgdp_tgp_meta.rownum`: str, `hgdp_tgp_meta.Pop.colors`: str, `hgdp_tgp_meta.Pop.shapes`: str}> fields. Counts by type:\n",
      "  str: 184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_qc: True\n",
      "variant_qc: True\n",
      "duplicate: True\n",
      "outlier_removal: False\n",
      "ld_pruning: False\n",
      "rel_unrel: default\n",
      "Running sample QC\n",
      "Running variant QC\n",
      "Removing duplicate sample\n"
     ]
    }
   ],
   "source": [
    "post_qc = read_qc(sample_qc=True, variant_qc=True, duplicate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409d2da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with variant QC filtering, this is taking over an hour to run\n",
    "post_qc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4edeb409",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 18:11:53 Hail: INFO: Loading 184 fields. Counts by type:\n",
      "  str: 184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_qc: False\n",
      "variant_qc: False\n",
      "duplicate: False\n",
      "outlier_removal: False\n",
      "Returning post QC matrix table with only related individuals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 18:13:39 Hail: INFO: hwe_normalize: found 248634 variants after filtering out monomorphic sites.\n",
      "2022-05-19 18:15:40 Hail: INFO: pca: running PCA with 20 components...\n",
      "2022-05-19 18:29:25 Hail: INFO: Wrote all 122 blocks of 248634 x 4119 matrix with block size 4096.\n",
      "2022-05-19 18:29:32 Hail: INFO: wrote matrix with 21 rows and 248634 columns as 61 blocks of size 4096 to /tmp/pcrelate-write-read-d2ooPbkImBuM0P1pUN2L4I.bm\n",
      "2022-05-19 18:29:51 Hail: INFO: wrote matrix with 248634 rows and 4119 columns as 122 blocks of size 4096 to /tmp/pcrelate-write-read-1TFgKH2XsifznqTgZeRKbX.bm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-146cccf76c95>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# testing out the time for running the related steps\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mrelated\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_qc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrel_unrel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'related'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-4-141e73e71a06>\u001B[0m in \u001B[0;36mread_qc\u001B[0;34m(sample_qc, variant_qc, duplicate, outlier_removal, ld_pruning, rel_unrel)\u001B[0m\n\u001B[1;32m    166\u001B[0m         \u001B[0;31m# identify related individuals in pairs to remove - returns a list of sample IDs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m         \u001B[0;31m# (~2hr & 22 min to run) - previous one took ~13min\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 168\u001B[0;31m         \u001B[0mrelated_samples_to_remove\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmaximal_independent_set\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrelatedness_ht\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrelatedness_ht\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    169\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-1450>\u001B[0m in \u001B[0;36mmaximal_independent_set\u001B[0;34m(i, j, keep, tie_breaker, keyed)\u001B[0m\n",
      "\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/hail/typecheck/check.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(__original_func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    575\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m__original_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    576\u001B[0m         \u001B[0margs_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_all\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m__original_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheckers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_method\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_method\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 577\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m__original_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    578\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    579\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/hail/methods/misc.py\u001B[0m in \u001B[0;36mmaximal_independent_set\u001B[0;34m(i, j, keep, tie_breaker, keyed)\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0medges\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m__i\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m__j\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkey_by\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'__i'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'__j'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m     \u001B[0medges_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew_temp_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 151\u001B[0;31m     \u001B[0medges\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0medges_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    152\u001B[0m     \u001B[0medges\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_table\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0medges_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-1162>\u001B[0m in \u001B[0;36mwrite\u001B[0;34m(self, output, overwrite, stage_locally, _codec_spec)\u001B[0m\n",
      "\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/hail/typecheck/check.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(__original_func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    575\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m__original_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    576\u001B[0m         \u001B[0margs_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_all\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m__original_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheckers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_method\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_method\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 577\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m__original_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs_\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    578\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    579\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/hail/table.py\u001B[0m in \u001B[0;36mwrite\u001B[0;34m(self, output, overwrite, stage_locally, _codec_spec)\u001B[0m\n\u001B[1;32m   1269\u001B[0m         \"\"\"\n\u001B[1;32m   1270\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1271\u001B[0;31m         \u001B[0mEnv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mir\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTableWrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mir\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTableNativeWriter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moverwrite\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstage_locally\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_codec_spec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1272\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1273\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_show\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwidth\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtruncate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtypes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/site-packages/hail/backend/py4j_backend.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, ir, timed)\u001B[0m\n\u001B[1;32m     84\u001B[0m         \u001B[0;31m# print(self._hail_package.expr.ir.Pretty.apply(jir, True, -1))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 86\u001B[0;31m             \u001B[0mresult_tuple\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jhc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuteEncode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream_codec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     87\u001B[0m             \u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimings\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mresult_tuple\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult_tuple\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mir\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtyp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_from_encoding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1301\u001B[0m             \u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEND_COMMAND_PART\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1303\u001B[0;31m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1304\u001B[0m         return_value = get_return_value(\n\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36msend_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[0mconnection\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_connection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1032\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1033\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconnection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1034\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1035\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_connection_guard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconnection\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36msend_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m   1198\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1199\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1200\u001B[0;31m             \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msmart_decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1201\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Answer received: {0}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1202\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproto\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRETURN_MESSAGE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/miniconda3/lib/python3.8/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    667\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    668\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 669\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    670\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_timeout_occurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# testing out the time for running the related steps\n",
    "# This is taking over an hour to run\n",
    "related = read_qc(rel_unrel='related')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0852d5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 15:54:39 Hail: INFO: Loading <StructExpression of type struct{s: str, `project_meta.sample_id`: str, `project_meta.research_project_key`: str, `project_meta.seq_project`: str, `project_meta.ccdg_alternate_sample_id`: str, `project_meta.ccdg_gender`: str, `project_meta.ccdg_center`: str, `project_meta.ccdg_study`: str, `project_meta.cram_path`: str, `project_meta.project_id`: str, `project_meta.v2_age`: str, `project_meta.v2_sex`: str, `project_meta.v2_hard_filters`: str, `project_meta.v2_perm_filters`: str, `project_meta.v2_pop_platform_filters`: str, `project_meta.v2_related`: str, `project_meta.v2_data_type`: str, `project_meta.v2_product`: str, `project_meta.v2_product_simplified`: str, `project_meta.v2_qc_platform`: str, `project_meta.v2_project_id`: str, `project_meta.v2_project_description`: str, `project_meta.v2_internal`: str, `project_meta.v2_investigator`: str, `project_meta.v2_known_pop`: str, `project_meta.v2_known_subpop`: str, `project_meta.v2_pop`: str, `project_meta.v2_subpop`: str, `project_meta.v2_neuro`: str, `project_meta.v2_control`: str, `project_meta.v2_topmed`: str, `project_meta.v2_high_quality`: str, `project_meta.v2_release`: str, `project_meta.v2_pcr_free`: str, `project_meta.v2_project_name`: str, `project_meta.v2_release_2_0_2`: str, `project_meta.project_ancestry`: str, `project_meta.project_pop`: str, `project_meta.project_subpop`: str, `project_meta.pdo_owner`: str, `project_meta.category`: str, `project_meta.contact_pi`: str, `project_meta.sample_pi`: str, `project_meta.pm`: str, `project_meta.research_project`: str, `project_meta.pdo`: str, `project_meta.title`: str, `project_meta.product`: str, `project_meta.probably_releasable`: str, `project_meta.releasable`: str, `project_meta.broad_external`: str, `project_meta.sex`: str, `project_meta.subpop_description`: str, `project_meta.exclude`: str, `project_meta.exclude_reason`: str, `project_meta.case_control`: str, `project_meta.age`: str, `project_meta.age_bin`: str, `project_meta.tcga_tumor`: str, `project_meta.age_alt`: str, `project_meta.v2_s_match`: str, `project_meta.topmed`: str, `project_meta.neuro_cohort`: str, `project_meta.neuro_case`: str, `subsets.non_topmed`: str, `subsets.controls_and_biobanks`: str, `subsets.non_neuro`: str, `subsets.non_v2`: str, `subsets.non_cancer`: str, `subsets.tgp`: str, `subsets.hgdp`: str, `bam_metrics.pct_bases_20x`: str, `bam_metrics.pct_chimeras`: str, `bam_metrics.freemix`: str, `bam_metrics.mean_coverage`: str, `bam_metrics.median_coverage`: str, `bam_metrics.mean_insert_size`: str, `bam_metrics.median_insert_size`: str, `bam_metrics.pct_bases_10x`: str, `sex_imputation.is_female`: str, `sex_imputation.chr20_mean_dp`: str, `sex_imputation.chrX_mean_dp`: str, `sex_imputation.chrY_mean_dp`: str, `sex_imputation.chrX_ploidy`: str, `sex_imputation.chrY_ploidy`: str, `sex_imputation.X_karyotype`: str, `sex_imputation.Y_karyotype`: str, `sex_imputation.sex_karyotype`: str, `sex_imputation.impute_sex_stats.f_stat`: str, `sex_imputation.impute_sex_stats.n_called`: str, `sex_imputation.impute_sex_stats.expected_homs`: str, `sex_imputation.impute_sex_stats.observed_homs`: str, `sample_qc.n_hom_ref`: str, `sample_qc.n_het`: str, `sample_qc.n_hom_var`: str, `sample_qc.n_non_ref`: str, `sample_qc.n_singleton`: str, `sample_qc.n_snp`: str, `sample_qc.n_insertion`: str, `sample_qc.n_deletion`: str, `sample_qc.n_transition`: str, `sample_qc.n_transversion`: str, `sample_qc.n_star`: str, `sample_qc.r_ti_tv`: str, `sample_qc.r_het_hom_var`: str, `sample_qc.r_insertion_deletion`: str, `sample_qc.n_snp_residual`: str, `sample_qc.n_singleton_residual`: str, `sample_qc.r_ti_tv_residual`: str, `sample_qc.r_insertion_deletion_residual`: str, `sample_qc.n_insertion_residual`: str, `sample_qc.n_deletion_residual`: str, `sample_qc.r_het_hom_var_residual`: str, `sample_qc.n_transition_residual`: str, `sample_qc.n_transversion_residual`: str, `population_inference.training_pop`: str, `population_inference.pca_scores`: str, `population_inference.pop`: str, `population_inference.prob_afr`: str, `population_inference.prob_ami`: str, `population_inference.prob_amr`: str, `population_inference.prob_asj`: str, `population_inference.prob_eas`: str, `population_inference.prob_fin`: str, `population_inference.prob_mid`: str, `population_inference.prob_nfe`: str, `population_inference.prob_oth`: str, `population_inference.prob_sas`: str, `population_inference.training_pop_all`: str, `sample_filters.sex_aneuploidy`: str, `sample_filters.insert_size`: str, `sample_filters.chimera`: str, `sample_filters.contamination`: str, `sample_filters.bad_qc_metrics`: str, `sample_filters.low_coverage`: str, `sample_filters.ambiguous_sex`: str, `sample_filters.failed_fingerprinting`: str, `sample_filters.TCGA_tumor_sample`: str, `sample_filters.hard_filters`: str, `sample_filters.hard_filtered`: str, `sample_filters.release_related`: str, `sample_filters.release_duplicate`: str, `sample_filters.release_parent_child`: str, `sample_filters.release_sibling`: str, `sample_filters.all_samples_related`: str, `sample_filters.all_samples_duplicate`: str, `sample_filters.all_samples_parent_child`: str, `sample_filters.all_samples_sibling`: str, `sample_filters.fail_n_snp_residual`: str, `sample_filters.fail_n_singleton_residual`: str, `sample_filters.fail_r_ti_tv_residual`: str, `sample_filters.fail_r_insertion_deletion_residual`: str, `sample_filters.fail_n_insertion_residual`: str, `sample_filters.fail_n_deletion_residual`: str, `sample_filters.fail_r_het_hom_var_residual`: str, `sample_filters.fail_n_transition_residual`: str, `sample_filters.fail_n_transversion_residual`: str, `sample_filters.qc_metrics_filters`: str, `relatedness_inference.relationships`: str, high_quality: str, release: str, `bergstrom.hgdp`: str, `bergstrom.lp`: str, `bergstrom.source`: str, `bergstrom.library_type`: str, `bergstrom.region`: str, `bergstrom.sex`: str, `bergstrom.coverage`: str, `bergstrom.freemix`: str, `bergstrom.capmq`: str, `bergstrom.insert_size_average`: str, `bergstrom.array_non_reference_discordance`: str, `bergstrom.sample`: str, `hgdp_tgp_meta.Project`: str, `hgdp_tgp_meta.Study.region`: str, `hgdp_tgp_meta.Population`: str, `hgdp_tgp_meta.Genetic.region`: str, `hgdp_tgp_meta.Latitude`: str, `hgdp_tgp_meta.Longitude`: str, `hgdp_tgp_meta.Continent.colors`: str, `hgdp_tgp_meta.n`: str, `hgdp_tgp_meta.rownum`: str, `hgdp_tgp_meta.Pop.colors`: str, `hgdp_tgp_meta.Pop.shapes`: str}> fields. Counts by type:\n",
      "  str: 184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_qc: False\n",
      "variant_qc: False\n",
      "duplicate: False\n",
      "outlier_removal: False\n",
      "ld_pruning: True\n",
      "rel_unrel: default\n"
     ]
    }
   ],
   "source": [
    "# This is reading in the ld pruned version of the dataset - takes negligible amount of time to run\n",
    "ld_pruned = read_qc(ld_pruning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a62ca38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Method to cut down run time: downsampling the dataset before running through filters\n",
    "# When I tried downsampling the same filters were still taking over an hour\n",
    "# the downsampled dataset will likely need to be written out?\n",
    "ds_cols_mt = pre_qc.sample_cols(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2090a1e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211358784, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_cols_mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8779a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Sizes of all the datasets:\n",
    "#Dataset Sizes - \n",
    "#    *gs://hgdp-1kg/hgdp_tgp/qc_and_figure_generation/pre_qc_final.mt\t3.33 TiB\n",
    "#    *gs://hgdp-1kg/post_qc_final.mt\t3.1 TiB\n",
    "#    gs://hgdp-1kg/hgdp_tgp/unrel_updated.mt\t13.15 GiB\n",
    "#    gs://hgdp-1kg/hgdp_tgp/rel_updated.mt\t4.11 GiB\n",
    "#    gs://hgdp-1kg/hgdp_tgp/intermediate_files/pre_running_varqc.mt\t3.11 TiB\n",
    "# *these two can be cut down. They are way too large to be used within the tutorials or to expect any user to store"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}